{
  "request_id": "REQ-20251109001427886198",
  "timestamp": "2025-11-09T00:14:27.886218",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 12575.010538101196,
  "retry_count": 0,
  "error_type": "SafetyFilterBlocked",
  "error_message": "Google Gemini blocked response. Finish reason: 2",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 2805
  },
  "stack_trace": "NoneType: None\n"
}
{
  "request_id": "REQ-20251109001427886198",
  "timestamp": "2025-11-09T00:14:27.886218",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 12575.74725151062,
  "retry_count": 0,
  "error_type": "ValueError",
  "error_message": "Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 2805
  },
  "stack_trace": "Traceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 485, in _generate_google\n    raise ValueError(f\"Google Gemini blocked response. Finish reason: {finish_reason}. Try with different prompt or use another provider.\")\nValueError: Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.\n"
}
{
  "request_id": "REQ-20251109001440462955",
  "timestamp": "2025-11-09T00:14:40.462976",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 15703.000545501709,
  "retry_count": 0,
  "error_type": "SafetyFilterBlocked",
  "error_message": "Google Gemini blocked response. Finish reason: 2",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 2805
  },
  "stack_trace": "Traceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 342, in generate\n    response = self._generate_fallback(prompt, system_prompt, model, temperature, max_tokens)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 667, in _generate_fallback\n    raise Exception(\"All providers failed. Check API keys and connectivity.\")\nException: All providers failed. Check API keys and connectivity.\n"
}
{
  "request_id": "REQ-20251109001440462955",
  "timestamp": "2025-11-09T00:14:40.462976",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 15703.914880752563,
  "retry_count": 0,
  "error_type": "ValueError",
  "error_message": "Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 2805
  },
  "stack_trace": "Traceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 342, in generate\n    response = self._generate_fallback(prompt, system_prompt, model, temperature, max_tokens)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 667, in _generate_fallback\n    raise Exception(\"All providers failed. Check API keys and connectivity.\")\nException: All providers failed. Check API keys and connectivity.\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 485, in _generate_google\n    raise ValueError(f\"Google Gemini blocked response. Finish reason: {finish_reason}. Try with different prompt or use another provider.\")\nValueError: Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.\n"
}
{
  "request_id": "REQ-20251109002028575093",
  "timestamp": "2025-11-09T00:20:28.575102",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 14114.94755744934,
  "retry_count": 0,
  "error_type": "SafetyFilterBlocked",
  "error_message": "Google Gemini blocked response. Finish reason: 2",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 793
  },
  "stack_trace": "NoneType: None\n"
}
{
  "request_id": "REQ-20251109002028575093",
  "timestamp": "2025-11-09T00:20:28.575102",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 14115.420818328857,
  "retry_count": 0,
  "error_type": "ValueError",
  "error_message": "Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 793
  },
  "stack_trace": "Traceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 485, in _generate_google\n    raise ValueError(f\"Google Gemini blocked response. Finish reason: {finish_reason}. Try with different prompt or use another provider.\")\nValueError: Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.\n"
}
{
  "request_id": "REQ-20251109002042691202",
  "timestamp": "2025-11-09T00:20:42.691214",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 14129.908084869385,
  "retry_count": 0,
  "error_type": "SafetyFilterBlocked",
  "error_message": "Google Gemini blocked response. Finish reason: 2",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 793
  },
  "stack_trace": "Traceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 342, in generate\n    response = self._generate_fallback(prompt, system_prompt, model, temperature, max_tokens)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 667, in _generate_fallback\n    raise Exception(\"All providers failed. Check API keys and connectivity.\")\nException: All providers failed. Check API keys and connectivity.\n"
}
{
  "request_id": "REQ-20251109002042691202",
  "timestamp": "2025-11-09T00:20:42.691214",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 14130.861043930054,
  "retry_count": 0,
  "error_type": "ValueError",
  "error_message": "Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 793
  },
  "stack_trace": "Traceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 342, in generate\n    response = self._generate_fallback(prompt, system_prompt, model, temperature, max_tokens)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 667, in _generate_fallback\n    raise Exception(\"All providers failed. Check API keys and connectivity.\")\nException: All providers failed. Check API keys and connectivity.\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 485, in _generate_google\n    raise ValueError(f\"Google Gemini blocked response. Finish reason: {finish_reason}. Try with different prompt or use another provider.\")\nValueError: Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.\n"
}
{
  "request_id": "REQ-20251109002215527119",
  "timestamp": "2025-11-09T00:22:15.527144",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 13864.133358001709,
  "retry_count": 0,
  "error_type": "SafetyFilterBlocked",
  "error_message": "Google Gemini blocked response. Finish reason: 2",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 793
  },
  "stack_trace": "NoneType: None\n"
}
{
  "request_id": "REQ-20251109002215527119",
  "timestamp": "2025-11-09T00:22:15.527144",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 13864.781856536865,
  "retry_count": 0,
  "error_type": "ValueError",
  "error_message": "Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 793
  },
  "stack_trace": "Traceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 485, in _generate_google\n    raise ValueError(f\"Google Gemini blocked response. Finish reason: {finish_reason}. Try with different prompt or use another provider.\")\nValueError: Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.\n"
}
{
  "request_id": "REQ-20251109002520940902",
  "timestamp": "2025-11-09T00:25:20.940916",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 14478.615999221802,
  "retry_count": 0,
  "error_type": "SafetyFilterBlocked",
  "error_message": "Google Gemini blocked response. Finish reason: 2",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 793
  },
  "stack_trace": "NoneType: None\n"
}
{
  "request_id": "REQ-20251109002520940902",
  "timestamp": "2025-11-09T00:25:20.940916",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 14479.128360748291,
  "retry_count": 0,
  "error_type": "ValueError",
  "error_message": "Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 793
  },
  "stack_trace": "Traceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 485, in _generate_google\n    raise ValueError(f\"Google Gemini blocked response. Finish reason: {finish_reason}. Try with different prompt or use another provider.\")\nValueError: Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.\n"
}
{
  "request_id": "REQ-20251109002535420761",
  "timestamp": "2025-11-09T00:25:35.420773",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 14061.4333152771,
  "retry_count": 0,
  "error_type": "SafetyFilterBlocked",
  "error_message": "Google Gemini blocked response. Finish reason: 2",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 793
  },
  "stack_trace": "Traceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 342, in generate\n    response = self._generate_fallback(prompt, system_prompt, model, temperature, max_tokens)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 667, in _generate_fallback\n    raise Exception(\"All providers failed. Check API keys and connectivity.\")\nException: All providers failed. Check API keys and connectivity.\n"
}
{
  "request_id": "REQ-20251109002535420761",
  "timestamp": "2025-11-09T00:25:35.420773",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 14062.871932983398,
  "retry_count": 0,
  "error_type": "ValueError",
  "error_message": "Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 793
  },
  "stack_trace": "Traceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 342, in generate\n    response = self._generate_fallback(prompt, system_prompt, model, temperature, max_tokens)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 667, in _generate_fallback\n    raise Exception(\"All providers failed. Check API keys and connectivity.\")\nException: All providers failed. Check API keys and connectivity.\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 485, in _generate_google\n    raise ValueError(f\"Google Gemini blocked response. Finish reason: {finish_reason}. Try with different prompt or use another provider.\")\nValueError: Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.\n"
}
{
  "request_id": "REQ-20251109003850137263",
  "timestamp": "2025-11-09T00:38:50.137290",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 16226.425886154175,
  "retry_count": 0,
  "error_type": "SafetyFilterBlocked",
  "error_message": "Google Gemini blocked response. Finish reason: 2",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 789
  },
  "stack_trace": "NoneType: None\n"
}
{
  "request_id": "REQ-20251109003850137263",
  "timestamp": "2025-11-09T00:38:50.137290",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 16227.976322174072,
  "retry_count": 0,
  "error_type": "ValueError",
  "error_message": "Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 789
  },
  "stack_trace": "Traceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 485, in _generate_google\n    raise ValueError(f\"Google Gemini blocked response. Finish reason: {finish_reason}. Try with different prompt or use another provider.\")\nValueError: Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.\n"
}
{
  "request_id": "REQ-20251109003906366369",
  "timestamp": "2025-11-09T00:39:06.366392",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 13718.48726272583,
  "retry_count": 0,
  "error_type": "SafetyFilterBlocked",
  "error_message": "Google Gemini blocked response. Finish reason: 2",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 789
  },
  "stack_trace": "Traceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 342, in generate\n    response = self._generate_fallback(prompt, system_prompt, model, temperature, max_tokens)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 667, in _generate_fallback\n    raise Exception(\"All providers failed. Check API keys and connectivity.\")\nException: All providers failed. Check API keys and connectivity.\n"
}
{
  "request_id": "REQ-20251109003906366369",
  "timestamp": "2025-11-09T00:39:06.366392",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 13719.179391860962,
  "retry_count": 0,
  "error_type": "ValueError",
  "error_message": "Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 789
  },
  "stack_trace": "Traceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 342, in generate\n    response = self._generate_fallback(prompt, system_prompt, model, temperature, max_tokens)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 667, in _generate_fallback\n    raise Exception(\"All providers failed. Check API keys and connectivity.\")\nException: All providers failed. Check API keys and connectivity.\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 485, in _generate_google\n    raise ValueError(f\"Google Gemini blocked response. Finish reason: {finish_reason}. Try with different prompt or use another provider.\")\nValueError: Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.\n"
}
{
  "request_id": "REQ-20251109004044975557",
  "timestamp": "2025-11-09T00:40:44.975571",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 13727.216958999634,
  "retry_count": 0,
  "error_type": "SafetyFilterBlocked",
  "error_message": "Google Gemini blocked response. Finish reason: 2",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 793
  },
  "stack_trace": "NoneType: None\n"
}
{
  "request_id": "REQ-20251109004044975557",
  "timestamp": "2025-11-09T00:40:44.975571",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 13727.627754211426,
  "retry_count": 0,
  "error_type": "ValueError",
  "error_message": "Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 793
  },
  "stack_trace": "Traceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 485, in _generate_google\n    raise ValueError(f\"Google Gemini blocked response. Finish reason: {finish_reason}. Try with different prompt or use another provider.\")\nValueError: Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.\n"
}
{
  "request_id": "REQ-20251109004135393006",
  "timestamp": "2025-11-09T00:41:35.393026",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 13172.198057174683,
  "retry_count": 0,
  "error_type": "SafetyFilterBlocked",
  "error_message": "Google Gemini blocked response. Finish reason: 2",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 789
  },
  "stack_trace": "NoneType: None\n"
}
{
  "request_id": "REQ-20251109004135393006",
  "timestamp": "2025-11-09T00:41:35.393026",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 13172.947406768799,
  "retry_count": 0,
  "error_type": "ValueError",
  "error_message": "Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 789
  },
  "stack_trace": "Traceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 485, in _generate_google\n    raise ValueError(f\"Google Gemini blocked response. Finish reason: {finish_reason}. Try with different prompt or use another provider.\")\nValueError: Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.\n"
}
{
  "request_id": "REQ-20251109004148566720",
  "timestamp": "2025-11-09T00:41:48.566738",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 14130.382537841797,
  "retry_count": 0,
  "error_type": "SafetyFilterBlocked",
  "error_message": "Google Gemini blocked response. Finish reason: 2",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 789
  },
  "stack_trace": "Traceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 342, in generate\n    response = self._generate_fallback(prompt, system_prompt, model, temperature, max_tokens)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 667, in _generate_fallback\n    raise Exception(\"All providers failed. Check API keys and connectivity.\")\nException: All providers failed. Check API keys and connectivity.\n"
}
{
  "request_id": "REQ-20251109004148566720",
  "timestamp": "2025-11-09T00:41:48.566738",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 14131.253004074097,
  "retry_count": 0,
  "error_type": "ValueError",
  "error_message": "Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 789
  },
  "stack_trace": "Traceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 342, in generate\n    response = self._generate_fallback(prompt, system_prompt, model, temperature, max_tokens)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 667, in _generate_fallback\n    raise Exception(\"All providers failed. Check API keys and connectivity.\")\nException: All providers failed. Check API keys and connectivity.\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 485, in _generate_google\n    raise ValueError(f\"Google Gemini blocked response. Finish reason: {finish_reason}. Try with different prompt or use another provider.\")\nValueError: Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.\n"
}
{
  "request_id": "REQ-20251109004228251855",
  "timestamp": "2025-11-09T00:42:28.251875",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 14484.555959701538,
  "retry_count": 0,
  "error_type": "SafetyFilterBlocked",
  "error_message": "Google Gemini blocked response. Finish reason: 2",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 787
  },
  "stack_trace": "NoneType: None\n"
}
{
  "request_id": "REQ-20251109004228251855",
  "timestamp": "2025-11-09T00:42:28.251875",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 14484.947681427002,
  "retry_count": 0,
  "error_type": "ValueError",
  "error_message": "Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 787
  },
  "stack_trace": "Traceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 485, in _generate_google\n    raise ValueError(f\"Google Gemini blocked response. Finish reason: {finish_reason}. Try with different prompt or use another provider.\")\nValueError: Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.\n"
}
{
  "request_id": "REQ-20251109004242737245",
  "timestamp": "2025-11-09T00:42:42.737257",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 13711.116790771484,
  "retry_count": 0,
  "error_type": "SafetyFilterBlocked",
  "error_message": "Google Gemini blocked response. Finish reason: 2",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 787
  },
  "stack_trace": "Traceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 342, in generate\n    response = self._generate_fallback(prompt, system_prompt, model, temperature, max_tokens)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 667, in _generate_fallback\n    raise Exception(\"All providers failed. Check API keys and connectivity.\")\nException: All providers failed. Check API keys and connectivity.\n"
}
{
  "request_id": "REQ-20251109004242737245",
  "timestamp": "2025-11-09T00:42:42.737257",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 13711.719512939453,
  "retry_count": 0,
  "error_type": "ValueError",
  "error_message": "Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 787
  },
  "stack_trace": "Traceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 342, in generate\n    response = self._generate_fallback(prompt, system_prompt, model, temperature, max_tokens)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 667, in _generate_fallback\n    raise Exception(\"All providers failed. Check API keys and connectivity.\")\nException: All providers failed. Check API keys and connectivity.\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 485, in _generate_google\n    raise ValueError(f\"Google Gemini blocked response. Finish reason: {finish_reason}. Try with different prompt or use another provider.\")\nValueError: Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.\n"
}
{
  "request_id": "REQ-20251109005607966639",
  "timestamp": "2025-11-09T00:56:07.966672",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 14792.606115341187,
  "retry_count": 0,
  "error_type": "SafetyFilterBlocked",
  "error_message": "Google Gemini blocked response. Finish reason: 2",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 793
  },
  "stack_trace": "NoneType: None\n"
}
{
  "request_id": "REQ-20251109005607966639",
  "timestamp": "2025-11-09T00:56:07.966672",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 14793.569326400757,
  "retry_count": 0,
  "error_type": "ValueError",
  "error_message": "Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 793
  },
  "stack_trace": "Traceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 518, in _generate_google\n    raise ValueError(f\"Google Gemini blocked response. Finish reason: {finish_reason}. Try with different prompt or use another provider.\")\nValueError: Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.\n"
}
{
  "request_id": "REQ-20251109005622761220",
  "timestamp": "2025-11-09T00:56:22.761236",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 14596.684217453003,
  "retry_count": 0,
  "error_type": "SafetyFilterBlocked",
  "error_message": "Google Gemini blocked response. Finish reason: 2",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 793
  },
  "stack_trace": "Traceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 364, in generate\n    response = self._generate_fallback(prompt, system_prompt, model, temperature, max_tokens)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 700, in _generate_fallback\n    raise Exception(\"All providers failed. Check API keys and connectivity.\")\nException: All providers failed. Check API keys and connectivity.\n"
}
{
  "request_id": "REQ-20251109005622761220",
  "timestamp": "2025-11-09T00:56:22.761236",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 14598.237991333008,
  "retry_count": 0,
  "error_type": "ValueError",
  "error_message": "Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 793
  },
  "stack_trace": "Traceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 364, in generate\n    response = self._generate_fallback(prompt, system_prompt, model, temperature, max_tokens)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 700, in _generate_fallback\n    raise Exception(\"All providers failed. Check API keys and connectivity.\")\nException: All providers failed. Check API keys and connectivity.\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 518, in _generate_google\n    raise ValueError(f\"Google Gemini blocked response. Finish reason: {finish_reason}. Try with different prompt or use another provider.\")\nValueError: Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.\n"
}
{
  "request_id": "REQ-20251109011526375950",
  "timestamp": "2025-11-09T01:15:26.375968",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 14123.990058898926,
  "retry_count": 0,
  "error_type": "SafetyFilterBlocked",
  "error_message": "Google Gemini blocked response. Finish reason: 2",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 793
  },
  "stack_trace": "NoneType: None\n"
}
{
  "request_id": "REQ-20251109011526375950",
  "timestamp": "2025-11-09T01:15:26.375968",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 14124.689102172852,
  "retry_count": 0,
  "error_type": "ValueError",
  "error_message": "Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 793
  },
  "stack_trace": "Traceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 518, in _generate_google\n    raise ValueError(f\"Google Gemini blocked response. Finish reason: {finish_reason}. Try with different prompt or use another provider.\")\nValueError: Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.\n"
}
{
  "request_id": "REQ-20251109011540501712",
  "timestamp": "2025-11-09T01:15:40.501729",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 13680.988073348999,
  "retry_count": 0,
  "error_type": "SafetyFilterBlocked",
  "error_message": "Google Gemini blocked response. Finish reason: 2",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 793
  },
  "stack_trace": "Traceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 364, in generate\n    response = self._generate_fallback(prompt, system_prompt, model, temperature, max_tokens)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 700, in _generate_fallback\n    raise Exception(\"All providers failed. Check API keys and connectivity.\")\nException: All providers failed. Check API keys and connectivity.\n"
}
{
  "request_id": "REQ-20251109011540501712",
  "timestamp": "2025-11-09T01:15:40.501729",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 13681.952714920044,
  "retry_count": 0,
  "error_type": "ValueError",
  "error_message": "Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 793
  },
  "stack_trace": "Traceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 364, in generate\n    response = self._generate_fallback(prompt, system_prompt, model, temperature, max_tokens)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 700, in _generate_fallback\n    raise Exception(\"All providers failed. Check API keys and connectivity.\")\nException: All providers failed. Check API keys and connectivity.\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 518, in _generate_google\n    raise ValueError(f\"Google Gemini blocked response. Finish reason: {finish_reason}. Try with different prompt or use another provider.\")\nValueError: Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.\n"
}
{
  "request_id": "REQ-20251109011634692154",
  "timestamp": "2025-11-09T01:16:34.692171",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 14110.063552856445,
  "retry_count": 0,
  "error_type": "SafetyFilterBlocked",
  "error_message": "Google Gemini blocked response. Finish reason: 2",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 793
  },
  "stack_trace": "NoneType: None\n"
}
{
  "request_id": "REQ-20251109011634692154",
  "timestamp": "2025-11-09T01:16:34.692171",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 14111.130714416504,
  "retry_count": 0,
  "error_type": "ValueError",
  "error_message": "Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 793
  },
  "stack_trace": "Traceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 518, in _generate_google\n    raise ValueError(f\"Google Gemini blocked response. Finish reason: {finish_reason}. Try with different prompt or use another provider.\")\nValueError: Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.\n"
}
{
  "request_id": "REQ-20251109011648804149",
  "timestamp": "2025-11-09T01:16:48.804165",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 14128.713846206665,
  "retry_count": 0,
  "error_type": "SafetyFilterBlocked",
  "error_message": "Google Gemini blocked response. Finish reason: 2",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 793
  },
  "stack_trace": "Traceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 364, in generate\n    response = self._generate_fallback(prompt, system_prompt, model, temperature, max_tokens)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 700, in _generate_fallback\n    raise Exception(\"All providers failed. Check API keys and connectivity.\")\nException: All providers failed. Check API keys and connectivity.\n"
}
{
  "request_id": "REQ-20251109011648804149",
  "timestamp": "2025-11-09T01:16:48.804165",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 14129.796743392944,
  "retry_count": 0,
  "error_type": "ValueError",
  "error_message": "Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 793
  },
  "stack_trace": "Traceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 364, in generate\n    response = self._generate_fallback(prompt, system_prompt, model, temperature, max_tokens)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 700, in _generate_fallback\n    raise Exception(\"All providers failed. Check API keys and connectivity.\")\nException: All providers failed. Check API keys and connectivity.\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 518, in _generate_google\n    raise ValueError(f\"Google Gemini blocked response. Finish reason: {finish_reason}. Try with different prompt or use another provider.\")\nValueError: Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.\n"
}
{
  "request_id": "REQ-20251109011719738135",
  "timestamp": "2025-11-09T01:17:19.738152",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 13700.570583343506,
  "retry_count": 0,
  "error_type": "SafetyFilterBlocked",
  "error_message": "Google Gemini blocked response. Finish reason: 2",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 777
  },
  "stack_trace": "NoneType: None\n"
}
{
  "request_id": "REQ-20251109011719738135",
  "timestamp": "2025-11-09T01:17:19.738152",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 13701.151132583618,
  "retry_count": 0,
  "error_type": "ValueError",
  "error_message": "Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 777
  },
  "stack_trace": "Traceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 518, in _generate_google\n    raise ValueError(f\"Google Gemini blocked response. Finish reason: {finish_reason}. Try with different prompt or use another provider.\")\nValueError: Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.\n"
}
{
  "request_id": "REQ-20251109011733439946",
  "timestamp": "2025-11-09T01:17:33.439960",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 13767.04716682434,
  "retry_count": 0,
  "error_type": "SafetyFilterBlocked",
  "error_message": "Google Gemini blocked response. Finish reason: 2",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 777
  },
  "stack_trace": "Traceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 364, in generate\n    response = self._generate_fallback(prompt, system_prompt, model, temperature, max_tokens)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 700, in _generate_fallback\n    raise Exception(\"All providers failed. Check API keys and connectivity.\")\nException: All providers failed. Check API keys and connectivity.\n"
}
{
  "request_id": "REQ-20251109011733439946",
  "timestamp": "2025-11-09T01:17:33.439960",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 13767.909526824951,
  "retry_count": 0,
  "error_type": "ValueError",
  "error_message": "Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 777
  },
  "stack_trace": "Traceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 364, in generate\n    response = self._generate_fallback(prompt, system_prompt, model, temperature, max_tokens)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 700, in _generate_fallback\n    raise Exception(\"All providers failed. Check API keys and connectivity.\")\nException: All providers failed. Check API keys and connectivity.\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 518, in _generate_google\n    raise ValueError(f\"Google Gemini blocked response. Finish reason: {finish_reason}. Try with different prompt or use another provider.\")\nValueError: Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.\n"
}
{
  "request_id": "REQ-20251109011747210336",
  "timestamp": "2025-11-09T01:17:47.210361",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 14847.238779067993,
  "retry_count": 0,
  "error_type": "SafetyFilterBlocked",
  "error_message": "Google Gemini blocked response. Finish reason: 2",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 793
  },
  "stack_trace": "NoneType: None\n"
}
{
  "request_id": "REQ-20251109011747210336",
  "timestamp": "2025-11-09T01:17:47.210361",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 14848.17123413086,
  "retry_count": 0,
  "error_type": "ValueError",
  "error_message": "Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 793
  },
  "stack_trace": "Traceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 518, in _generate_google\n    raise ValueError(f\"Google Gemini blocked response. Finish reason: {finish_reason}. Try with different prompt or use another provider.\")\nValueError: Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.\n"
}
{
  "request_id": "REQ-20251109011802059636",
  "timestamp": "2025-11-09T01:18:02.059664",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 13642.126083374023,
  "retry_count": 0,
  "error_type": "SafetyFilterBlocked",
  "error_message": "Google Gemini blocked response. Finish reason: 2",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 793
  },
  "stack_trace": "Traceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 364, in generate\n    response = self._generate_fallback(prompt, system_prompt, model, temperature, max_tokens)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 700, in _generate_fallback\n    raise Exception(\"All providers failed. Check API keys and connectivity.\")\nException: All providers failed. Check API keys and connectivity.\n"
}
{
  "request_id": "REQ-20251109011802059636",
  "timestamp": "2025-11-09T01:18:02.059664",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 13643.216371536255,
  "retry_count": 0,
  "error_type": "ValueError",
  "error_message": "Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 793
  },
  "stack_trace": "Traceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 364, in generate\n    response = self._generate_fallback(prompt, system_prompt, model, temperature, max_tokens)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 700, in _generate_fallback\n    raise Exception(\"All providers failed. Check API keys and connectivity.\")\nException: All providers failed. Check API keys and connectivity.\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 518, in _generate_google\n    raise ValueError(f\"Google Gemini blocked response. Finish reason: {finish_reason}. Try with different prompt or use another provider.\")\nValueError: Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.\n"
}
{
  "request_id": "REQ-20251109011924497658",
  "timestamp": "2025-11-09T01:19:24.497678",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 14257.649183273315,
  "retry_count": 0,
  "error_type": "SafetyFilterBlocked",
  "error_message": "Google Gemini blocked response. Finish reason: 2",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 1040
  },
  "stack_trace": "NoneType: None\n"
}
{
  "request_id": "REQ-20251109011924497658",
  "timestamp": "2025-11-09T01:19:24.497678",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 14258.038520812988,
  "retry_count": 0,
  "error_type": "ValueError",
  "error_message": "Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 1040
  },
  "stack_trace": "Traceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 518, in _generate_google\n    raise ValueError(f\"Google Gemini blocked response. Finish reason: {finish_reason}. Try with different prompt or use another provider.\")\nValueError: Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.\n"
}
{
  "request_id": "REQ-20251109011954360875",
  "timestamp": "2025-11-09T01:19:54.360892",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 14121.83666229248,
  "retry_count": 0,
  "error_type": "SafetyFilterBlocked",
  "error_message": "Google Gemini blocked response. Finish reason: 2",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 777
  },
  "stack_trace": "NoneType: None\n"
}
{
  "request_id": "REQ-20251109011954360875",
  "timestamp": "2025-11-09T01:19:54.360892",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 14122.496843338013,
  "retry_count": 0,
  "error_type": "ValueError",
  "error_message": "Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 777
  },
  "stack_trace": "Traceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 518, in _generate_google\n    raise ValueError(f\"Google Gemini blocked response. Finish reason: {finish_reason}. Try with different prompt or use another provider.\")\nValueError: Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.\n"
}
{
  "request_id": "REQ-20251109012008484073",
  "timestamp": "2025-11-09T01:20:08.484091",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 14130.939722061157,
  "retry_count": 0,
  "error_type": "SafetyFilterBlocked",
  "error_message": "Google Gemini blocked response. Finish reason: 2",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 777
  },
  "stack_trace": "Traceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 364, in generate\n    response = self._generate_fallback(prompt, system_prompt, model, temperature, max_tokens)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 700, in _generate_fallback\n    raise Exception(\"All providers failed. Check API keys and connectivity.\")\nException: All providers failed. Check API keys and connectivity.\n"
}
{
  "request_id": "REQ-20251109012008484073",
  "timestamp": "2025-11-09T01:20:08.484091",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 14131.814956665039,
  "retry_count": 0,
  "error_type": "ValueError",
  "error_message": "Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 777
  },
  "stack_trace": "Traceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 364, in generate\n    response = self._generate_fallback(prompt, system_prompt, model, temperature, max_tokens)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 700, in _generate_fallback\n    raise Exception(\"All providers failed. Check API keys and connectivity.\")\nException: All providers failed. Check API keys and connectivity.\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 518, in _generate_google\n    raise ValueError(f\"Google Gemini blocked response. Finish reason: {finish_reason}. Try with different prompt or use another provider.\")\nValueError: Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.\n"
}
{
  "request_id": "REQ-20251109012022618448",
  "timestamp": "2025-11-09T01:20:22.618465",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 14602.162837982178,
  "retry_count": 0,
  "error_type": "SafetyFilterBlocked",
  "error_message": "Google Gemini blocked response. Finish reason: 2",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 777
  },
  "stack_trace": "NoneType: None\n"
}
{
  "request_id": "REQ-20251109012022618448",
  "timestamp": "2025-11-09T01:20:22.618465",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 14603.102922439575,
  "retry_count": 0,
  "error_type": "ValueError",
  "error_message": "Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 777
  },
  "stack_trace": "Traceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 518, in _generate_google\n    raise ValueError(f\"Google Gemini blocked response. Finish reason: {finish_reason}. Try with different prompt or use another provider.\")\nValueError: Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.\n"
}
{
  "request_id": "REQ-20251109012037222912",
  "timestamp": "2025-11-09T01:20:37.222941",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 14252.992391586304,
  "retry_count": 0,
  "error_type": "SafetyFilterBlocked",
  "error_message": "Google Gemini blocked response. Finish reason: 2",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 777
  },
  "stack_trace": "Traceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 364, in generate\n    response = self._generate_fallback(prompt, system_prompt, model, temperature, max_tokens)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 700, in _generate_fallback\n    raise Exception(\"All providers failed. Check API keys and connectivity.\")\nException: All providers failed. Check API keys and connectivity.\n"
}
{
  "request_id": "REQ-20251109012037222912",
  "timestamp": "2025-11-09T01:20:37.222941",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 14254.316091537476,
  "retry_count": 0,
  "error_type": "ValueError",
  "error_message": "Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 777
  },
  "stack_trace": "Traceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 364, in generate\n    response = self._generate_fallback(prompt, system_prompt, model, temperature, max_tokens)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 700, in _generate_fallback\n    raise Exception(\"All providers failed. Check API keys and connectivity.\")\nException: All providers failed. Check API keys and connectivity.\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 518, in _generate_google\n    raise ValueError(f\"Google Gemini blocked response. Finish reason: {finish_reason}. Try with different prompt or use another provider.\")\nValueError: Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.\n"
}
{
  "request_id": "REQ-20251109012051480903",
  "timestamp": "2025-11-09T01:20:51.480929",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 15371.021509170532,
  "retry_count": 0,
  "error_type": "SafetyFilterBlocked",
  "error_message": "Google Gemini blocked response. Finish reason: 2",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 777
  },
  "stack_trace": "NoneType: None\n"
}
{
  "request_id": "REQ-20251109012051480903",
  "timestamp": "2025-11-09T01:20:51.480929",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 15371.620655059814,
  "retry_count": 0,
  "error_type": "ValueError",
  "error_message": "Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 777
  },
  "stack_trace": "Traceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 518, in _generate_google\n    raise ValueError(f\"Google Gemini blocked response. Finish reason: {finish_reason}. Try with different prompt or use another provider.\")\nValueError: Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.\n"
}
{
  "request_id": "REQ-20251109012106853171",
  "timestamp": "2025-11-09T01:21:06.853186",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 13720.351696014404,
  "retry_count": 0,
  "error_type": "SafetyFilterBlocked",
  "error_message": "Google Gemini blocked response. Finish reason: 2",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 777
  },
  "stack_trace": "Traceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 364, in generate\n    response = self._generate_fallback(prompt, system_prompt, model, temperature, max_tokens)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 700, in _generate_fallback\n    raise Exception(\"All providers failed. Check API keys and connectivity.\")\nException: All providers failed. Check API keys and connectivity.\n"
}
{
  "request_id": "REQ-20251109012106853171",
  "timestamp": "2025-11-09T01:21:06.853186",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 13721.778392791748,
  "retry_count": 0,
  "error_type": "ValueError",
  "error_message": "Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 777
  },
  "stack_trace": "Traceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 364, in generate\n    response = self._generate_fallback(prompt, system_prompt, model, temperature, max_tokens)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 700, in _generate_fallback\n    raise Exception(\"All providers failed. Check API keys and connectivity.\")\nException: All providers failed. Check API keys and connectivity.\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 518, in _generate_google\n    raise ValueError(f\"Google Gemini blocked response. Finish reason: {finish_reason}. Try with different prompt or use another provider.\")\nValueError: Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.\n"
}
{
  "request_id": "REQ-20251109012120580378",
  "timestamp": "2025-11-09T01:21:20.580395",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 13688.206434249878,
  "retry_count": 0,
  "error_type": "SafetyFilterBlocked",
  "error_message": "Google Gemini blocked response. Finish reason: 2",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 777
  },
  "stack_trace": "NoneType: None\n"
}
{
  "request_id": "REQ-20251109012120580378",
  "timestamp": "2025-11-09T01:21:20.580395",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 13689.115285873413,
  "retry_count": 0,
  "error_type": "ValueError",
  "error_message": "Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 777
  },
  "stack_trace": "Traceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 518, in _generate_google\n    raise ValueError(f\"Google Gemini blocked response. Finish reason: {finish_reason}. Try with different prompt or use another provider.\")\nValueError: Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.\n"
}
{
  "request_id": "REQ-20251109012201953029",
  "timestamp": "2025-11-09T01:22:01.953049",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 12739.110946655273,
  "retry_count": 0,
  "error_type": "SafetyFilterBlocked",
  "error_message": "Google Gemini blocked response. Finish reason: 2",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 777
  },
  "stack_trace": "NoneType: None\n"
}
{
  "request_id": "REQ-20251109012201953029",
  "timestamp": "2025-11-09T01:22:01.953049",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 12740.132093429565,
  "retry_count": 0,
  "error_type": "ValueError",
  "error_message": "Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 777
  },
  "stack_trace": "Traceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 518, in _generate_google\n    raise ValueError(f\"Google Gemini blocked response. Finish reason: {finish_reason}. Try with different prompt or use another provider.\")\nValueError: Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.\n"
}
{
  "request_id": "REQ-20251109012256785435",
  "timestamp": "2025-11-09T01:22:56.785450",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 14883.657932281494,
  "retry_count": 0,
  "error_type": "SafetyFilterBlocked",
  "error_message": "Google Gemini blocked response. Finish reason: 2",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 793
  },
  "stack_trace": "NoneType: None\n"
}
{
  "request_id": "REQ-20251109012256785435",
  "timestamp": "2025-11-09T01:22:56.785450",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 14884.346008300781,
  "retry_count": 0,
  "error_type": "ValueError",
  "error_message": "Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 793
  },
  "stack_trace": "Traceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 518, in _generate_google\n    raise ValueError(f\"Google Gemini blocked response. Finish reason: {finish_reason}. Try with different prompt or use another provider.\")\nValueError: Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.\n"
}
{
  "request_id": "REQ-20251109012311670873",
  "timestamp": "2025-11-09T01:23:11.670890",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 13831.520080566406,
  "retry_count": 0,
  "error_type": "SafetyFilterBlocked",
  "error_message": "Google Gemini blocked response. Finish reason: 2",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 793
  },
  "stack_trace": "Traceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 364, in generate\n    response = self._generate_fallback(prompt, system_prompt, model, temperature, max_tokens)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 700, in _generate_fallback\n    raise Exception(\"All providers failed. Check API keys and connectivity.\")\nException: All providers failed. Check API keys and connectivity.\n"
}
{
  "request_id": "REQ-20251109012311670873",
  "timestamp": "2025-11-09T01:23:11.670890",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 13832.124710083008,
  "retry_count": 0,
  "error_type": "ValueError",
  "error_message": "Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 793
  },
  "stack_trace": "Traceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 364, in generate\n    response = self._generate_fallback(prompt, system_prompt, model, temperature, max_tokens)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 700, in _generate_fallback\n    raise Exception(\"All providers failed. Check API keys and connectivity.\")\nException: All providers failed. Check API keys and connectivity.\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 518, in _generate_google\n    raise ValueError(f\"Google Gemini blocked response. Finish reason: {finish_reason}. Try with different prompt or use another provider.\")\nValueError: Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.\n"
}
{
  "request_id": "REQ-20251109012339350673",
  "timestamp": "2025-11-09T01:23:39.350693",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 16256.90484046936,
  "retry_count": 0,
  "error_type": "SafetyFilterBlocked",
  "error_message": "Google Gemini blocked response. Finish reason: 2",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3500,
    "prompt_length": 871
  },
  "stack_trace": "NoneType: None\n"
}
{
  "request_id": "REQ-20251109012339350673",
  "timestamp": "2025-11-09T01:23:39.350693",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 16257.481813430786,
  "retry_count": 0,
  "error_type": "ValueError",
  "error_message": "Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3500,
    "prompt_length": 871
  },
  "stack_trace": "Traceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 518, in _generate_google\n    raise ValueError(f\"Google Gemini blocked response. Finish reason: {finish_reason}. Try with different prompt or use another provider.\")\nValueError: Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.\n"
}
{
  "request_id": "REQ-20251109012939829735",
  "timestamp": "2025-11-09T01:29:39.829745",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 14180.733919143677,
  "retry_count": 0,
  "error_type": "SafetyFilterBlocked",
  "error_message": "Google Gemini blocked response. Finish reason: 2",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 793
  },
  "stack_trace": "NoneType: None\n"
}
{
  "request_id": "REQ-20251109012939829735",
  "timestamp": "2025-11-09T01:29:39.829745",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 14181.585788726807,
  "retry_count": 0,
  "error_type": "ValueError",
  "error_message": "Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 793
  },
  "stack_trace": "Traceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 518, in _generate_google\n    raise ValueError(f\"Google Gemini blocked response. Finish reason: {finish_reason}. Try with different prompt or use another provider.\")\nValueError: Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.\n"
}
{
  "request_id": "REQ-20251109012954012366",
  "timestamp": "2025-11-09T01:29:54.012384",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 13616.856575012207,
  "retry_count": 0,
  "error_type": "SafetyFilterBlocked",
  "error_message": "Google Gemini blocked response. Finish reason: 2",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 793
  },
  "stack_trace": "Traceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 364, in generate\n    response = self._generate_fallback(prompt, system_prompt, model, temperature, max_tokens)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 700, in _generate_fallback\n    raise Exception(\"All providers failed. Check API keys and connectivity.\")\nException: All providers failed. Check API keys and connectivity.\n"
}
{
  "request_id": "REQ-20251109012954012366",
  "timestamp": "2025-11-09T01:29:54.012384",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 13617.769479751587,
  "retry_count": 0,
  "error_type": "ValueError",
  "error_message": "Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 793
  },
  "stack_trace": "Traceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 364, in generate\n    response = self._generate_fallback(prompt, system_prompt, model, temperature, max_tokens)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 700, in _generate_fallback\n    raise Exception(\"All providers failed. Check API keys and connectivity.\")\nException: All providers failed. Check API keys and connectivity.\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 518, in _generate_google\n    raise ValueError(f\"Google Gemini blocked response. Finish reason: {finish_reason}. Try with different prompt or use another provider.\")\nValueError: Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.\n"
}
{
  "request_id": "REQ-20251109013137914131",
  "timestamp": "2025-11-09T01:31:37.914146",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 13727.375030517578,
  "retry_count": 0,
  "error_type": "SafetyFilterBlocked",
  "error_message": "Google Gemini blocked response. Finish reason: 2",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 798
  },
  "stack_trace": "NoneType: None\n"
}
{
  "request_id": "REQ-20251109013137914131",
  "timestamp": "2025-11-09T01:31:37.914146",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 13728.486061096191,
  "retry_count": 0,
  "error_type": "ValueError",
  "error_message": "Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 798
  },
  "stack_trace": "Traceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 518, in _generate_google\n    raise ValueError(f\"Google Gemini blocked response. Finish reason: {finish_reason}. Try with different prompt or use another provider.\")\nValueError: Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.\n"
}
{
  "request_id": "REQ-20251109013151643375",
  "timestamp": "2025-11-09T01:31:51.643391",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 14360.154867172241,
  "retry_count": 0,
  "error_type": "SafetyFilterBlocked",
  "error_message": "Google Gemini blocked response. Finish reason: 2",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 798
  },
  "stack_trace": "Traceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 364, in generate\n    response = self._generate_fallback(prompt, system_prompt, model, temperature, max_tokens)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 700, in _generate_fallback\n    raise Exception(\"All providers failed. Check API keys and connectivity.\")\nException: All providers failed. Check API keys and connectivity.\n"
}
{
  "request_id": "REQ-20251109013151643375",
  "timestamp": "2025-11-09T01:31:51.643391",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 14361.538887023926,
  "retry_count": 0,
  "error_type": "ValueError",
  "error_message": "Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 798
  },
  "stack_trace": "Traceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 364, in generate\n    response = self._generate_fallback(prompt, system_prompt, model, temperature, max_tokens)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 700, in _generate_fallback\n    raise Exception(\"All providers failed. Check API keys and connectivity.\")\nException: All providers failed. Check API keys and connectivity.\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 518, in _generate_google\n    raise ValueError(f\"Google Gemini blocked response. Finish reason: {finish_reason}. Try with different prompt or use another provider.\")\nValueError: Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.\n"
}
{
  "request_id": "REQ-20251109013223139335",
  "timestamp": "2025-11-09T01:32:23.139362",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 13584.1965675354,
  "retry_count": 0,
  "error_type": "SafetyFilterBlocked",
  "error_message": "Google Gemini blocked response. Finish reason: 2",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 792
  },
  "stack_trace": "NoneType: None\n"
}
{
  "request_id": "REQ-20251109013223139335",
  "timestamp": "2025-11-09T01:32:23.139362",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 13584.773540496826,
  "retry_count": 0,
  "error_type": "ValueError",
  "error_message": "Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 792
  },
  "stack_trace": "Traceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 518, in _generate_google\n    raise ValueError(f\"Google Gemini blocked response. Finish reason: {finish_reason}. Try with different prompt or use another provider.\")\nValueError: Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.\n"
}
{
  "request_id": "REQ-20251109013737194292",
  "timestamp": "2025-11-09T01:37:37.194309",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 13591.455698013306,
  "retry_count": 0,
  "error_type": "SafetyFilterBlocked",
  "error_message": "Google Gemini blocked response. Finish reason: 2",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 789
  },
  "stack_trace": "NoneType: None\n"
}
{
  "request_id": "REQ-20251109013737194292",
  "timestamp": "2025-11-09T01:37:37.194309",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 13591.87936782837,
  "retry_count": 0,
  "error_type": "ValueError",
  "error_message": "Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 789
  },
  "stack_trace": "Traceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 518, in _generate_google\n    raise ValueError(f\"Google Gemini blocked response. Finish reason: {finish_reason}. Try with different prompt or use another provider.\")\nValueError: Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.\n"
}
{
  "request_id": "REQ-20251109013750786840",
  "timestamp": "2025-11-09T01:37:50.786851",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 13824.573516845703,
  "retry_count": 0,
  "error_type": "SafetyFilterBlocked",
  "error_message": "Google Gemini blocked response. Finish reason: 2",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 789
  },
  "stack_trace": "Traceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 364, in generate\n    response = self._generate_fallback(prompt, system_prompt, model, temperature, max_tokens)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 700, in _generate_fallback\n    raise Exception(\"All providers failed. Check API keys and connectivity.\")\nException: All providers failed. Check API keys and connectivity.\n"
}
{
  "request_id": "REQ-20251109013750786840",
  "timestamp": "2025-11-09T01:37:50.786851",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 13825.464010238647,
  "retry_count": 0,
  "error_type": "ValueError",
  "error_message": "Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 789
  },
  "stack_trace": "Traceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 364, in generate\n    response = self._generate_fallback(prompt, system_prompt, model, temperature, max_tokens)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 700, in _generate_fallback\n    raise Exception(\"All providers failed. Check API keys and connectivity.\")\nException: All providers failed. Check API keys and connectivity.\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 518, in _generate_google\n    raise ValueError(f\"Google Gemini blocked response. Finish reason: {finish_reason}. Try with different prompt or use another provider.\")\nValueError: Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.\n"
}
