{
  "request_id": "REQ-20251109001427886198",
  "timestamp": "2025-11-09T00:14:27.886218",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 12575.010538101196,
  "retry_count": 0,
  "error_type": "SafetyFilterBlocked",
  "error_message": "Google Gemini blocked response. Finish reason: 2",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 2805
  },
  "stack_trace": "NoneType: None\n"
}
{
  "request_id": "REQ-20251109001427886198",
  "timestamp": "2025-11-09T00:14:27.886218",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 12575.74725151062,
  "retry_count": 0,
  "error_type": "ValueError",
  "error_message": "Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 2805
  },
  "stack_trace": "Traceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 485, in _generate_google\n    raise ValueError(f\"Google Gemini blocked response. Finish reason: {finish_reason}. Try with different prompt or use another provider.\")\nValueError: Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.\n"
}
{
  "request_id": "REQ-20251109001440462955",
  "timestamp": "2025-11-09T00:14:40.462976",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 15703.000545501709,
  "retry_count": 0,
  "error_type": "SafetyFilterBlocked",
  "error_message": "Google Gemini blocked response. Finish reason: 2",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 2805
  },
  "stack_trace": "Traceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 342, in generate\n    response = self._generate_fallback(prompt, system_prompt, model, temperature, max_tokens)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 667, in _generate_fallback\n    raise Exception(\"All providers failed. Check API keys and connectivity.\")\nException: All providers failed. Check API keys and connectivity.\n"
}
{
  "request_id": "REQ-20251109001440462955",
  "timestamp": "2025-11-09T00:14:40.462976",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 15703.914880752563,
  "retry_count": 0,
  "error_type": "ValueError",
  "error_message": "Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 2805
  },
  "stack_trace": "Traceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 342, in generate\n    response = self._generate_fallback(prompt, system_prompt, model, temperature, max_tokens)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 667, in _generate_fallback\n    raise Exception(\"All providers failed. Check API keys and connectivity.\")\nException: All providers failed. Check API keys and connectivity.\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 485, in _generate_google\n    raise ValueError(f\"Google Gemini blocked response. Finish reason: {finish_reason}. Try with different prompt or use another provider.\")\nValueError: Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.\n"
}
{
  "request_id": "REQ-20251109002028575093",
  "timestamp": "2025-11-09T00:20:28.575102",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 14114.94755744934,
  "retry_count": 0,
  "error_type": "SafetyFilterBlocked",
  "error_message": "Google Gemini blocked response. Finish reason: 2",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 793
  },
  "stack_trace": "NoneType: None\n"
}
{
  "request_id": "REQ-20251109002028575093",
  "timestamp": "2025-11-09T00:20:28.575102",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 14115.420818328857,
  "retry_count": 0,
  "error_type": "ValueError",
  "error_message": "Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 793
  },
  "stack_trace": "Traceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 485, in _generate_google\n    raise ValueError(f\"Google Gemini blocked response. Finish reason: {finish_reason}. Try with different prompt or use another provider.\")\nValueError: Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.\n"
}
{
  "request_id": "REQ-20251109002042691202",
  "timestamp": "2025-11-09T00:20:42.691214",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 14129.908084869385,
  "retry_count": 0,
  "error_type": "SafetyFilterBlocked",
  "error_message": "Google Gemini blocked response. Finish reason: 2",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 793
  },
  "stack_trace": "Traceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 342, in generate\n    response = self._generate_fallback(prompt, system_prompt, model, temperature, max_tokens)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 667, in _generate_fallback\n    raise Exception(\"All providers failed. Check API keys and connectivity.\")\nException: All providers failed. Check API keys and connectivity.\n"
}
{
  "request_id": "REQ-20251109002042691202",
  "timestamp": "2025-11-09T00:20:42.691214",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 14130.861043930054,
  "retry_count": 0,
  "error_type": "ValueError",
  "error_message": "Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 793
  },
  "stack_trace": "Traceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 342, in generate\n    response = self._generate_fallback(prompt, system_prompt, model, temperature, max_tokens)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 667, in _generate_fallback\n    raise Exception(\"All providers failed. Check API keys and connectivity.\")\nException: All providers failed. Check API keys and connectivity.\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 485, in _generate_google\n    raise ValueError(f\"Google Gemini blocked response. Finish reason: {finish_reason}. Try with different prompt or use another provider.\")\nValueError: Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.\n"
}
{
  "request_id": "REQ-20251109002215527119",
  "timestamp": "2025-11-09T00:22:15.527144",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 13864.133358001709,
  "retry_count": 0,
  "error_type": "SafetyFilterBlocked",
  "error_message": "Google Gemini blocked response. Finish reason: 2",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 793
  },
  "stack_trace": "NoneType: None\n"
}
{
  "request_id": "REQ-20251109002215527119",
  "timestamp": "2025-11-09T00:22:15.527144",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 13864.781856536865,
  "retry_count": 0,
  "error_type": "ValueError",
  "error_message": "Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 793
  },
  "stack_trace": "Traceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 485, in _generate_google\n    raise ValueError(f\"Google Gemini blocked response. Finish reason: {finish_reason}. Try with different prompt or use another provider.\")\nValueError: Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.\n"
}
{
  "request_id": "REQ-20251109002520940902",
  "timestamp": "2025-11-09T00:25:20.940916",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 14478.615999221802,
  "retry_count": 0,
  "error_type": "SafetyFilterBlocked",
  "error_message": "Google Gemini blocked response. Finish reason: 2",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 793
  },
  "stack_trace": "NoneType: None\n"
}
{
  "request_id": "REQ-20251109002520940902",
  "timestamp": "2025-11-09T00:25:20.940916",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 14479.128360748291,
  "retry_count": 0,
  "error_type": "ValueError",
  "error_message": "Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 793
  },
  "stack_trace": "Traceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 485, in _generate_google\n    raise ValueError(f\"Google Gemini blocked response. Finish reason: {finish_reason}. Try with different prompt or use another provider.\")\nValueError: Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.\n"
}
{
  "request_id": "REQ-20251109002535420761",
  "timestamp": "2025-11-09T00:25:35.420773",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 14061.4333152771,
  "retry_count": 0,
  "error_type": "SafetyFilterBlocked",
  "error_message": "Google Gemini blocked response. Finish reason: 2",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 793
  },
  "stack_trace": "Traceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 342, in generate\n    response = self._generate_fallback(prompt, system_prompt, model, temperature, max_tokens)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 667, in _generate_fallback\n    raise Exception(\"All providers failed. Check API keys and connectivity.\")\nException: All providers failed. Check API keys and connectivity.\n"
}
{
  "request_id": "REQ-20251109002535420761",
  "timestamp": "2025-11-09T00:25:35.420773",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 14062.871932983398,
  "retry_count": 0,
  "error_type": "ValueError",
  "error_message": "Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 793
  },
  "stack_trace": "Traceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 342, in generate\n    response = self._generate_fallback(prompt, system_prompt, model, temperature, max_tokens)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 667, in _generate_fallback\n    raise Exception(\"All providers failed. Check API keys and connectivity.\")\nException: All providers failed. Check API keys and connectivity.\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 485, in _generate_google\n    raise ValueError(f\"Google Gemini blocked response. Finish reason: {finish_reason}. Try with different prompt or use another provider.\")\nValueError: Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.\n"
}
{
  "request_id": "REQ-20251109003850137263",
  "timestamp": "2025-11-09T00:38:50.137290",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 16226.425886154175,
  "retry_count": 0,
  "error_type": "SafetyFilterBlocked",
  "error_message": "Google Gemini blocked response. Finish reason: 2",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 789
  },
  "stack_trace": "NoneType: None\n"
}
{
  "request_id": "REQ-20251109003850137263",
  "timestamp": "2025-11-09T00:38:50.137290",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 16227.976322174072,
  "retry_count": 0,
  "error_type": "ValueError",
  "error_message": "Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 789
  },
  "stack_trace": "Traceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 485, in _generate_google\n    raise ValueError(f\"Google Gemini blocked response. Finish reason: {finish_reason}. Try with different prompt or use another provider.\")\nValueError: Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.\n"
}
{
  "request_id": "REQ-20251109003906366369",
  "timestamp": "2025-11-09T00:39:06.366392",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 13718.48726272583,
  "retry_count": 0,
  "error_type": "SafetyFilterBlocked",
  "error_message": "Google Gemini blocked response. Finish reason: 2",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 789
  },
  "stack_trace": "Traceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 342, in generate\n    response = self._generate_fallback(prompt, system_prompt, model, temperature, max_tokens)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 667, in _generate_fallback\n    raise Exception(\"All providers failed. Check API keys and connectivity.\")\nException: All providers failed. Check API keys and connectivity.\n"
}
{
  "request_id": "REQ-20251109003906366369",
  "timestamp": "2025-11-09T00:39:06.366392",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 13719.179391860962,
  "retry_count": 0,
  "error_type": "ValueError",
  "error_message": "Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 789
  },
  "stack_trace": "Traceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 342, in generate\n    response = self._generate_fallback(prompt, system_prompt, model, temperature, max_tokens)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 667, in _generate_fallback\n    raise Exception(\"All providers failed. Check API keys and connectivity.\")\nException: All providers failed. Check API keys and connectivity.\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 485, in _generate_google\n    raise ValueError(f\"Google Gemini blocked response. Finish reason: {finish_reason}. Try with different prompt or use another provider.\")\nValueError: Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.\n"
}
{
  "request_id": "REQ-20251109004044975557",
  "timestamp": "2025-11-09T00:40:44.975571",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 13727.216958999634,
  "retry_count": 0,
  "error_type": "SafetyFilterBlocked",
  "error_message": "Google Gemini blocked response. Finish reason: 2",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 793
  },
  "stack_trace": "NoneType: None\n"
}
{
  "request_id": "REQ-20251109004044975557",
  "timestamp": "2025-11-09T00:40:44.975571",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 13727.627754211426,
  "retry_count": 0,
  "error_type": "ValueError",
  "error_message": "Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 793
  },
  "stack_trace": "Traceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 485, in _generate_google\n    raise ValueError(f\"Google Gemini blocked response. Finish reason: {finish_reason}. Try with different prompt or use another provider.\")\nValueError: Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.\n"
}
{
  "request_id": "REQ-20251109004135393006",
  "timestamp": "2025-11-09T00:41:35.393026",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 13172.198057174683,
  "retry_count": 0,
  "error_type": "SafetyFilterBlocked",
  "error_message": "Google Gemini blocked response. Finish reason: 2",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 789
  },
  "stack_trace": "NoneType: None\n"
}
{
  "request_id": "REQ-20251109004135393006",
  "timestamp": "2025-11-09T00:41:35.393026",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 13172.947406768799,
  "retry_count": 0,
  "error_type": "ValueError",
  "error_message": "Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 789
  },
  "stack_trace": "Traceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 485, in _generate_google\n    raise ValueError(f\"Google Gemini blocked response. Finish reason: {finish_reason}. Try with different prompt or use another provider.\")\nValueError: Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.\n"
}
{
  "request_id": "REQ-20251109004148566720",
  "timestamp": "2025-11-09T00:41:48.566738",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 14130.382537841797,
  "retry_count": 0,
  "error_type": "SafetyFilterBlocked",
  "error_message": "Google Gemini blocked response. Finish reason: 2",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 789
  },
  "stack_trace": "Traceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 342, in generate\n    response = self._generate_fallback(prompt, system_prompt, model, temperature, max_tokens)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 667, in _generate_fallback\n    raise Exception(\"All providers failed. Check API keys and connectivity.\")\nException: All providers failed. Check API keys and connectivity.\n"
}
{
  "request_id": "REQ-20251109004148566720",
  "timestamp": "2025-11-09T00:41:48.566738",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 14131.253004074097,
  "retry_count": 0,
  "error_type": "ValueError",
  "error_message": "Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 789
  },
  "stack_trace": "Traceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 342, in generate\n    response = self._generate_fallback(prompt, system_prompt, model, temperature, max_tokens)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 667, in _generate_fallback\n    raise Exception(\"All providers failed. Check API keys and connectivity.\")\nException: All providers failed. Check API keys and connectivity.\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 485, in _generate_google\n    raise ValueError(f\"Google Gemini blocked response. Finish reason: {finish_reason}. Try with different prompt or use another provider.\")\nValueError: Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.\n"
}
{
  "request_id": "REQ-20251109004228251855",
  "timestamp": "2025-11-09T00:42:28.251875",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 14484.555959701538,
  "retry_count": 0,
  "error_type": "SafetyFilterBlocked",
  "error_message": "Google Gemini blocked response. Finish reason: 2",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 787
  },
  "stack_trace": "NoneType: None\n"
}
{
  "request_id": "REQ-20251109004228251855",
  "timestamp": "2025-11-09T00:42:28.251875",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 14484.947681427002,
  "retry_count": 0,
  "error_type": "ValueError",
  "error_message": "Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 787
  },
  "stack_trace": "Traceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 485, in _generate_google\n    raise ValueError(f\"Google Gemini blocked response. Finish reason: {finish_reason}. Try with different prompt or use another provider.\")\nValueError: Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.\n"
}
{
  "request_id": "REQ-20251109004242737245",
  "timestamp": "2025-11-09T00:42:42.737257",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 13711.116790771484,
  "retry_count": 0,
  "error_type": "SafetyFilterBlocked",
  "error_message": "Google Gemini blocked response. Finish reason: 2",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 787
  },
  "stack_trace": "Traceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 342, in generate\n    response = self._generate_fallback(prompt, system_prompt, model, temperature, max_tokens)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 667, in _generate_fallback\n    raise Exception(\"All providers failed. Check API keys and connectivity.\")\nException: All providers failed. Check API keys and connectivity.\n"
}
{
  "request_id": "REQ-20251109004242737245",
  "timestamp": "2025-11-09T00:42:42.737257",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 13711.719512939453,
  "retry_count": 0,
  "error_type": "ValueError",
  "error_message": "Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 787
  },
  "stack_trace": "Traceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 342, in generate\n    response = self._generate_fallback(prompt, system_prompt, model, temperature, max_tokens)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 667, in _generate_fallback\n    raise Exception(\"All providers failed. Check API keys and connectivity.\")\nException: All providers failed. Check API keys and connectivity.\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 485, in _generate_google\n    raise ValueError(f\"Google Gemini blocked response. Finish reason: {finish_reason}. Try with different prompt or use another provider.\")\nValueError: Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.\n"
}
{
  "request_id": "REQ-20251109005607966639",
  "timestamp": "2025-11-09T00:56:07.966672",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 14792.606115341187,
  "retry_count": 0,
  "error_type": "SafetyFilterBlocked",
  "error_message": "Google Gemini blocked response. Finish reason: 2",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 793
  },
  "stack_trace": "NoneType: None\n"
}
{
  "request_id": "REQ-20251109005607966639",
  "timestamp": "2025-11-09T00:56:07.966672",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 14793.569326400757,
  "retry_count": 0,
  "error_type": "ValueError",
  "error_message": "Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 793
  },
  "stack_trace": "Traceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 518, in _generate_google\n    raise ValueError(f\"Google Gemini blocked response. Finish reason: {finish_reason}. Try with different prompt or use another provider.\")\nValueError: Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.\n"
}
{
  "request_id": "REQ-20251109005622761220",
  "timestamp": "2025-11-09T00:56:22.761236",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 14596.684217453003,
  "retry_count": 0,
  "error_type": "SafetyFilterBlocked",
  "error_message": "Google Gemini blocked response. Finish reason: 2",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 793
  },
  "stack_trace": "Traceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 364, in generate\n    response = self._generate_fallback(prompt, system_prompt, model, temperature, max_tokens)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 700, in _generate_fallback\n    raise Exception(\"All providers failed. Check API keys and connectivity.\")\nException: All providers failed. Check API keys and connectivity.\n"
}
{
  "request_id": "REQ-20251109005622761220",
  "timestamp": "2025-11-09T00:56:22.761236",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 14598.237991333008,
  "retry_count": 0,
  "error_type": "ValueError",
  "error_message": "Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 793
  },
  "stack_trace": "Traceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 364, in generate\n    response = self._generate_fallback(prompt, system_prompt, model, temperature, max_tokens)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 700, in _generate_fallback\n    raise Exception(\"All providers failed. Check API keys and connectivity.\")\nException: All providers failed. Check API keys and connectivity.\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 518, in _generate_google\n    raise ValueError(f\"Google Gemini blocked response. Finish reason: {finish_reason}. Try with different prompt or use another provider.\")\nValueError: Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.\n"
}
{
  "request_id": "REQ-20251109011526375950",
  "timestamp": "2025-11-09T01:15:26.375968",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 14123.990058898926,
  "retry_count": 0,
  "error_type": "SafetyFilterBlocked",
  "error_message": "Google Gemini blocked response. Finish reason: 2",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 793
  },
  "stack_trace": "NoneType: None\n"
}
{
  "request_id": "REQ-20251109011526375950",
  "timestamp": "2025-11-09T01:15:26.375968",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 14124.689102172852,
  "retry_count": 0,
  "error_type": "ValueError",
  "error_message": "Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 793
  },
  "stack_trace": "Traceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 518, in _generate_google\n    raise ValueError(f\"Google Gemini blocked response. Finish reason: {finish_reason}. Try with different prompt or use another provider.\")\nValueError: Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.\n"
}
{
  "request_id": "REQ-20251109011540501712",
  "timestamp": "2025-11-09T01:15:40.501729",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 13680.988073348999,
  "retry_count": 0,
  "error_type": "SafetyFilterBlocked",
  "error_message": "Google Gemini blocked response. Finish reason: 2",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 793
  },
  "stack_trace": "Traceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 364, in generate\n    response = self._generate_fallback(prompt, system_prompt, model, temperature, max_tokens)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 700, in _generate_fallback\n    raise Exception(\"All providers failed. Check API keys and connectivity.\")\nException: All providers failed. Check API keys and connectivity.\n"
}
{
  "request_id": "REQ-20251109011540501712",
  "timestamp": "2025-11-09T01:15:40.501729",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 13681.952714920044,
  "retry_count": 0,
  "error_type": "ValueError",
  "error_message": "Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 793
  },
  "stack_trace": "Traceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 364, in generate\n    response = self._generate_fallback(prompt, system_prompt, model, temperature, max_tokens)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 700, in _generate_fallback\n    raise Exception(\"All providers failed. Check API keys and connectivity.\")\nException: All providers failed. Check API keys and connectivity.\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 518, in _generate_google\n    raise ValueError(f\"Google Gemini blocked response. Finish reason: {finish_reason}. Try with different prompt or use another provider.\")\nValueError: Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.\n"
}
{
  "request_id": "REQ-20251109011634692154",
  "timestamp": "2025-11-09T01:16:34.692171",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 14110.063552856445,
  "retry_count": 0,
  "error_type": "SafetyFilterBlocked",
  "error_message": "Google Gemini blocked response. Finish reason: 2",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 793
  },
  "stack_trace": "NoneType: None\n"
}
{
  "request_id": "REQ-20251109011634692154",
  "timestamp": "2025-11-09T01:16:34.692171",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 14111.130714416504,
  "retry_count": 0,
  "error_type": "ValueError",
  "error_message": "Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 793
  },
  "stack_trace": "Traceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 518, in _generate_google\n    raise ValueError(f\"Google Gemini blocked response. Finish reason: {finish_reason}. Try with different prompt or use another provider.\")\nValueError: Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.\n"
}
{
  "request_id": "REQ-20251109011648804149",
  "timestamp": "2025-11-09T01:16:48.804165",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 14128.713846206665,
  "retry_count": 0,
  "error_type": "SafetyFilterBlocked",
  "error_message": "Google Gemini blocked response. Finish reason: 2",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 793
  },
  "stack_trace": "Traceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 364, in generate\n    response = self._generate_fallback(prompt, system_prompt, model, temperature, max_tokens)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 700, in _generate_fallback\n    raise Exception(\"All providers failed. Check API keys and connectivity.\")\nException: All providers failed. Check API keys and connectivity.\n"
}
{
  "request_id": "REQ-20251109011648804149",
  "timestamp": "2025-11-09T01:16:48.804165",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 14129.796743392944,
  "retry_count": 0,
  "error_type": "ValueError",
  "error_message": "Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 793
  },
  "stack_trace": "Traceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 364, in generate\n    response = self._generate_fallback(prompt, system_prompt, model, temperature, max_tokens)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 700, in _generate_fallback\n    raise Exception(\"All providers failed. Check API keys and connectivity.\")\nException: All providers failed. Check API keys and connectivity.\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 518, in _generate_google\n    raise ValueError(f\"Google Gemini blocked response. Finish reason: {finish_reason}. Try with different prompt or use another provider.\")\nValueError: Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.\n"
}
{
  "request_id": "REQ-20251109011719738135",
  "timestamp": "2025-11-09T01:17:19.738152",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 13700.570583343506,
  "retry_count": 0,
  "error_type": "SafetyFilterBlocked",
  "error_message": "Google Gemini blocked response. Finish reason: 2",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 777
  },
  "stack_trace": "NoneType: None\n"
}
{
  "request_id": "REQ-20251109011719738135",
  "timestamp": "2025-11-09T01:17:19.738152",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 13701.151132583618,
  "retry_count": 0,
  "error_type": "ValueError",
  "error_message": "Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 777
  },
  "stack_trace": "Traceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 518, in _generate_google\n    raise ValueError(f\"Google Gemini blocked response. Finish reason: {finish_reason}. Try with different prompt or use another provider.\")\nValueError: Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.\n"
}
{
  "request_id": "REQ-20251109011733439946",
  "timestamp": "2025-11-09T01:17:33.439960",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 13767.04716682434,
  "retry_count": 0,
  "error_type": "SafetyFilterBlocked",
  "error_message": "Google Gemini blocked response. Finish reason: 2",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 777
  },
  "stack_trace": "Traceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 364, in generate\n    response = self._generate_fallback(prompt, system_prompt, model, temperature, max_tokens)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 700, in _generate_fallback\n    raise Exception(\"All providers failed. Check API keys and connectivity.\")\nException: All providers failed. Check API keys and connectivity.\n"
}
{
  "request_id": "REQ-20251109011733439946",
  "timestamp": "2025-11-09T01:17:33.439960",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 13767.909526824951,
  "retry_count": 0,
  "error_type": "ValueError",
  "error_message": "Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 777
  },
  "stack_trace": "Traceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 364, in generate\n    response = self._generate_fallback(prompt, system_prompt, model, temperature, max_tokens)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 700, in _generate_fallback\n    raise Exception(\"All providers failed. Check API keys and connectivity.\")\nException: All providers failed. Check API keys and connectivity.\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 518, in _generate_google\n    raise ValueError(f\"Google Gemini blocked response. Finish reason: {finish_reason}. Try with different prompt or use another provider.\")\nValueError: Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.\n"
}
{
  "request_id": "REQ-20251109011747210336",
  "timestamp": "2025-11-09T01:17:47.210361",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 14847.238779067993,
  "retry_count": 0,
  "error_type": "SafetyFilterBlocked",
  "error_message": "Google Gemini blocked response. Finish reason: 2",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 793
  },
  "stack_trace": "NoneType: None\n"
}
{
  "request_id": "REQ-20251109011747210336",
  "timestamp": "2025-11-09T01:17:47.210361",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 14848.17123413086,
  "retry_count": 0,
  "error_type": "ValueError",
  "error_message": "Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 793
  },
  "stack_trace": "Traceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 518, in _generate_google\n    raise ValueError(f\"Google Gemini blocked response. Finish reason: {finish_reason}. Try with different prompt or use another provider.\")\nValueError: Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.\n"
}
{
  "request_id": "REQ-20251109011802059636",
  "timestamp": "2025-11-09T01:18:02.059664",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 13642.126083374023,
  "retry_count": 0,
  "error_type": "SafetyFilterBlocked",
  "error_message": "Google Gemini blocked response. Finish reason: 2",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 793
  },
  "stack_trace": "Traceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 364, in generate\n    response = self._generate_fallback(prompt, system_prompt, model, temperature, max_tokens)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 700, in _generate_fallback\n    raise Exception(\"All providers failed. Check API keys and connectivity.\")\nException: All providers failed. Check API keys and connectivity.\n"
}
{
  "request_id": "REQ-20251109011802059636",
  "timestamp": "2025-11-09T01:18:02.059664",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 13643.216371536255,
  "retry_count": 0,
  "error_type": "ValueError",
  "error_message": "Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 793
  },
  "stack_trace": "Traceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 364, in generate\n    response = self._generate_fallback(prompt, system_prompt, model, temperature, max_tokens)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 700, in _generate_fallback\n    raise Exception(\"All providers failed. Check API keys and connectivity.\")\nException: All providers failed. Check API keys and connectivity.\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 518, in _generate_google\n    raise ValueError(f\"Google Gemini blocked response. Finish reason: {finish_reason}. Try with different prompt or use another provider.\")\nValueError: Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.\n"
}
{
  "request_id": "REQ-20251109011924497658",
  "timestamp": "2025-11-09T01:19:24.497678",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 14257.649183273315,
  "retry_count": 0,
  "error_type": "SafetyFilterBlocked",
  "error_message": "Google Gemini blocked response. Finish reason: 2",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 1040
  },
  "stack_trace": "NoneType: None\n"
}
{
  "request_id": "REQ-20251109011924497658",
  "timestamp": "2025-11-09T01:19:24.497678",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 14258.038520812988,
  "retry_count": 0,
  "error_type": "ValueError",
  "error_message": "Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 1040
  },
  "stack_trace": "Traceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 518, in _generate_google\n    raise ValueError(f\"Google Gemini blocked response. Finish reason: {finish_reason}. Try with different prompt or use another provider.\")\nValueError: Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.\n"
}
{
  "request_id": "REQ-20251109011954360875",
  "timestamp": "2025-11-09T01:19:54.360892",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 14121.83666229248,
  "retry_count": 0,
  "error_type": "SafetyFilterBlocked",
  "error_message": "Google Gemini blocked response. Finish reason: 2",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 777
  },
  "stack_trace": "NoneType: None\n"
}
{
  "request_id": "REQ-20251109011954360875",
  "timestamp": "2025-11-09T01:19:54.360892",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 14122.496843338013,
  "retry_count": 0,
  "error_type": "ValueError",
  "error_message": "Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 777
  },
  "stack_trace": "Traceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 518, in _generate_google\n    raise ValueError(f\"Google Gemini blocked response. Finish reason: {finish_reason}. Try with different prompt or use another provider.\")\nValueError: Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.\n"
}
{
  "request_id": "REQ-20251109012008484073",
  "timestamp": "2025-11-09T01:20:08.484091",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 14130.939722061157,
  "retry_count": 0,
  "error_type": "SafetyFilterBlocked",
  "error_message": "Google Gemini blocked response. Finish reason: 2",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 777
  },
  "stack_trace": "Traceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 364, in generate\n    response = self._generate_fallback(prompt, system_prompt, model, temperature, max_tokens)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 700, in _generate_fallback\n    raise Exception(\"All providers failed. Check API keys and connectivity.\")\nException: All providers failed. Check API keys and connectivity.\n"
}
{
  "request_id": "REQ-20251109012008484073",
  "timestamp": "2025-11-09T01:20:08.484091",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 14131.814956665039,
  "retry_count": 0,
  "error_type": "ValueError",
  "error_message": "Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 777
  },
  "stack_trace": "Traceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 364, in generate\n    response = self._generate_fallback(prompt, system_prompt, model, temperature, max_tokens)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 700, in _generate_fallback\n    raise Exception(\"All providers failed. Check API keys and connectivity.\")\nException: All providers failed. Check API keys and connectivity.\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 518, in _generate_google\n    raise ValueError(f\"Google Gemini blocked response. Finish reason: {finish_reason}. Try with different prompt or use another provider.\")\nValueError: Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.\n"
}
{
  "request_id": "REQ-20251109012022618448",
  "timestamp": "2025-11-09T01:20:22.618465",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 14602.162837982178,
  "retry_count": 0,
  "error_type": "SafetyFilterBlocked",
  "error_message": "Google Gemini blocked response. Finish reason: 2",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 777
  },
  "stack_trace": "NoneType: None\n"
}
{
  "request_id": "REQ-20251109012022618448",
  "timestamp": "2025-11-09T01:20:22.618465",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 14603.102922439575,
  "retry_count": 0,
  "error_type": "ValueError",
  "error_message": "Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 777
  },
  "stack_trace": "Traceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 518, in _generate_google\n    raise ValueError(f\"Google Gemini blocked response. Finish reason: {finish_reason}. Try with different prompt or use another provider.\")\nValueError: Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.\n"
}
{
  "request_id": "REQ-20251109012037222912",
  "timestamp": "2025-11-09T01:20:37.222941",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 14252.992391586304,
  "retry_count": 0,
  "error_type": "SafetyFilterBlocked",
  "error_message": "Google Gemini blocked response. Finish reason: 2",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 777
  },
  "stack_trace": "Traceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 364, in generate\n    response = self._generate_fallback(prompt, system_prompt, model, temperature, max_tokens)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 700, in _generate_fallback\n    raise Exception(\"All providers failed. Check API keys and connectivity.\")\nException: All providers failed. Check API keys and connectivity.\n"
}
{
  "request_id": "REQ-20251109012037222912",
  "timestamp": "2025-11-09T01:20:37.222941",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 14254.316091537476,
  "retry_count": 0,
  "error_type": "ValueError",
  "error_message": "Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 777
  },
  "stack_trace": "Traceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 364, in generate\n    response = self._generate_fallback(prompt, system_prompt, model, temperature, max_tokens)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 700, in _generate_fallback\n    raise Exception(\"All providers failed. Check API keys and connectivity.\")\nException: All providers failed. Check API keys and connectivity.\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 518, in _generate_google\n    raise ValueError(f\"Google Gemini blocked response. Finish reason: {finish_reason}. Try with different prompt or use another provider.\")\nValueError: Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.\n"
}
{
  "request_id": "REQ-20251109012051480903",
  "timestamp": "2025-11-09T01:20:51.480929",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 15371.021509170532,
  "retry_count": 0,
  "error_type": "SafetyFilterBlocked",
  "error_message": "Google Gemini blocked response. Finish reason: 2",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 777
  },
  "stack_trace": "NoneType: None\n"
}
{
  "request_id": "REQ-20251109012051480903",
  "timestamp": "2025-11-09T01:20:51.480929",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 15371.620655059814,
  "retry_count": 0,
  "error_type": "ValueError",
  "error_message": "Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 777
  },
  "stack_trace": "Traceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 518, in _generate_google\n    raise ValueError(f\"Google Gemini blocked response. Finish reason: {finish_reason}. Try with different prompt or use another provider.\")\nValueError: Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.\n"
}
{
  "request_id": "REQ-20251109012106853171",
  "timestamp": "2025-11-09T01:21:06.853186",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 13720.351696014404,
  "retry_count": 0,
  "error_type": "SafetyFilterBlocked",
  "error_message": "Google Gemini blocked response. Finish reason: 2",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 777
  },
  "stack_trace": "Traceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 364, in generate\n    response = self._generate_fallback(prompt, system_prompt, model, temperature, max_tokens)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 700, in _generate_fallback\n    raise Exception(\"All providers failed. Check API keys and connectivity.\")\nException: All providers failed. Check API keys and connectivity.\n"
}
{
  "request_id": "REQ-20251109012106853171",
  "timestamp": "2025-11-09T01:21:06.853186",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 13721.778392791748,
  "retry_count": 0,
  "error_type": "ValueError",
  "error_message": "Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 777
  },
  "stack_trace": "Traceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 364, in generate\n    response = self._generate_fallback(prompt, system_prompt, model, temperature, max_tokens)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 700, in _generate_fallback\n    raise Exception(\"All providers failed. Check API keys and connectivity.\")\nException: All providers failed. Check API keys and connectivity.\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 518, in _generate_google\n    raise ValueError(f\"Google Gemini blocked response. Finish reason: {finish_reason}. Try with different prompt or use another provider.\")\nValueError: Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.\n"
}
{
  "request_id": "REQ-20251109012120580378",
  "timestamp": "2025-11-09T01:21:20.580395",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 13688.206434249878,
  "retry_count": 0,
  "error_type": "SafetyFilterBlocked",
  "error_message": "Google Gemini blocked response. Finish reason: 2",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 777
  },
  "stack_trace": "NoneType: None\n"
}
{
  "request_id": "REQ-20251109012120580378",
  "timestamp": "2025-11-09T01:21:20.580395",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 13689.115285873413,
  "retry_count": 0,
  "error_type": "ValueError",
  "error_message": "Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 777
  },
  "stack_trace": "Traceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 518, in _generate_google\n    raise ValueError(f\"Google Gemini blocked response. Finish reason: {finish_reason}. Try with different prompt or use another provider.\")\nValueError: Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.\n"
}
{
  "request_id": "REQ-20251109012201953029",
  "timestamp": "2025-11-09T01:22:01.953049",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 12739.110946655273,
  "retry_count": 0,
  "error_type": "SafetyFilterBlocked",
  "error_message": "Google Gemini blocked response. Finish reason: 2",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 777
  },
  "stack_trace": "NoneType: None\n"
}
{
  "request_id": "REQ-20251109012201953029",
  "timestamp": "2025-11-09T01:22:01.953049",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 12740.132093429565,
  "retry_count": 0,
  "error_type": "ValueError",
  "error_message": "Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 777
  },
  "stack_trace": "Traceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 518, in _generate_google\n    raise ValueError(f\"Google Gemini blocked response. Finish reason: {finish_reason}. Try with different prompt or use another provider.\")\nValueError: Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.\n"
}
{
  "request_id": "REQ-20251109012256785435",
  "timestamp": "2025-11-09T01:22:56.785450",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 14883.657932281494,
  "retry_count": 0,
  "error_type": "SafetyFilterBlocked",
  "error_message": "Google Gemini blocked response. Finish reason: 2",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 793
  },
  "stack_trace": "NoneType: None\n"
}
{
  "request_id": "REQ-20251109012256785435",
  "timestamp": "2025-11-09T01:22:56.785450",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 14884.346008300781,
  "retry_count": 0,
  "error_type": "ValueError",
  "error_message": "Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 793
  },
  "stack_trace": "Traceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 518, in _generate_google\n    raise ValueError(f\"Google Gemini blocked response. Finish reason: {finish_reason}. Try with different prompt or use another provider.\")\nValueError: Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.\n"
}
{
  "request_id": "REQ-20251109012311670873",
  "timestamp": "2025-11-09T01:23:11.670890",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 13831.520080566406,
  "retry_count": 0,
  "error_type": "SafetyFilterBlocked",
  "error_message": "Google Gemini blocked response. Finish reason: 2",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 793
  },
  "stack_trace": "Traceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 364, in generate\n    response = self._generate_fallback(prompt, system_prompt, model, temperature, max_tokens)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 700, in _generate_fallback\n    raise Exception(\"All providers failed. Check API keys and connectivity.\")\nException: All providers failed. Check API keys and connectivity.\n"
}
{
  "request_id": "REQ-20251109012311670873",
  "timestamp": "2025-11-09T01:23:11.670890",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 13832.124710083008,
  "retry_count": 0,
  "error_type": "ValueError",
  "error_message": "Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 793
  },
  "stack_trace": "Traceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 364, in generate\n    response = self._generate_fallback(prompt, system_prompt, model, temperature, max_tokens)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 700, in _generate_fallback\n    raise Exception(\"All providers failed. Check API keys and connectivity.\")\nException: All providers failed. Check API keys and connectivity.\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 518, in _generate_google\n    raise ValueError(f\"Google Gemini blocked response. Finish reason: {finish_reason}. Try with different prompt or use another provider.\")\nValueError: Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.\n"
}
{
  "request_id": "REQ-20251109012339350673",
  "timestamp": "2025-11-09T01:23:39.350693",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 16256.90484046936,
  "retry_count": 0,
  "error_type": "SafetyFilterBlocked",
  "error_message": "Google Gemini blocked response. Finish reason: 2",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3500,
    "prompt_length": 871
  },
  "stack_trace": "NoneType: None\n"
}
{
  "request_id": "REQ-20251109012339350673",
  "timestamp": "2025-11-09T01:23:39.350693",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 16257.481813430786,
  "retry_count": 0,
  "error_type": "ValueError",
  "error_message": "Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3500,
    "prompt_length": 871
  },
  "stack_trace": "Traceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 518, in _generate_google\n    raise ValueError(f\"Google Gemini blocked response. Finish reason: {finish_reason}. Try with different prompt or use another provider.\")\nValueError: Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.\n"
}
{
  "request_id": "REQ-20251109012939829735",
  "timestamp": "2025-11-09T01:29:39.829745",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 14180.733919143677,
  "retry_count": 0,
  "error_type": "SafetyFilterBlocked",
  "error_message": "Google Gemini blocked response. Finish reason: 2",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 793
  },
  "stack_trace": "NoneType: None\n"
}
{
  "request_id": "REQ-20251109012939829735",
  "timestamp": "2025-11-09T01:29:39.829745",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 14181.585788726807,
  "retry_count": 0,
  "error_type": "ValueError",
  "error_message": "Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 793
  },
  "stack_trace": "Traceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 518, in _generate_google\n    raise ValueError(f\"Google Gemini blocked response. Finish reason: {finish_reason}. Try with different prompt or use another provider.\")\nValueError: Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.\n"
}
{
  "request_id": "REQ-20251109012954012366",
  "timestamp": "2025-11-09T01:29:54.012384",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 13616.856575012207,
  "retry_count": 0,
  "error_type": "SafetyFilterBlocked",
  "error_message": "Google Gemini blocked response. Finish reason: 2",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 793
  },
  "stack_trace": "Traceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 364, in generate\n    response = self._generate_fallback(prompt, system_prompt, model, temperature, max_tokens)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 700, in _generate_fallback\n    raise Exception(\"All providers failed. Check API keys and connectivity.\")\nException: All providers failed. Check API keys and connectivity.\n"
}
{
  "request_id": "REQ-20251109012954012366",
  "timestamp": "2025-11-09T01:29:54.012384",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 13617.769479751587,
  "retry_count": 0,
  "error_type": "ValueError",
  "error_message": "Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 793
  },
  "stack_trace": "Traceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 364, in generate\n    response = self._generate_fallback(prompt, system_prompt, model, temperature, max_tokens)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 700, in _generate_fallback\n    raise Exception(\"All providers failed. Check API keys and connectivity.\")\nException: All providers failed. Check API keys and connectivity.\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 518, in _generate_google\n    raise ValueError(f\"Google Gemini blocked response. Finish reason: {finish_reason}. Try with different prompt or use another provider.\")\nValueError: Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.\n"
}
{
  "request_id": "REQ-20251109013137914131",
  "timestamp": "2025-11-09T01:31:37.914146",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 13727.375030517578,
  "retry_count": 0,
  "error_type": "SafetyFilterBlocked",
  "error_message": "Google Gemini blocked response. Finish reason: 2",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 798
  },
  "stack_trace": "NoneType: None\n"
}
{
  "request_id": "REQ-20251109013137914131",
  "timestamp": "2025-11-09T01:31:37.914146",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 13728.486061096191,
  "retry_count": 0,
  "error_type": "ValueError",
  "error_message": "Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 798
  },
  "stack_trace": "Traceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 518, in _generate_google\n    raise ValueError(f\"Google Gemini blocked response. Finish reason: {finish_reason}. Try with different prompt or use another provider.\")\nValueError: Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.\n"
}
{
  "request_id": "REQ-20251109013151643375",
  "timestamp": "2025-11-09T01:31:51.643391",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 14360.154867172241,
  "retry_count": 0,
  "error_type": "SafetyFilterBlocked",
  "error_message": "Google Gemini blocked response. Finish reason: 2",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 798
  },
  "stack_trace": "Traceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 364, in generate\n    response = self._generate_fallback(prompt, system_prompt, model, temperature, max_tokens)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 700, in _generate_fallback\n    raise Exception(\"All providers failed. Check API keys and connectivity.\")\nException: All providers failed. Check API keys and connectivity.\n"
}
{
  "request_id": "REQ-20251109013151643375",
  "timestamp": "2025-11-09T01:31:51.643391",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 14361.538887023926,
  "retry_count": 0,
  "error_type": "ValueError",
  "error_message": "Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 798
  },
  "stack_trace": "Traceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 364, in generate\n    response = self._generate_fallback(prompt, system_prompt, model, temperature, max_tokens)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 700, in _generate_fallback\n    raise Exception(\"All providers failed. Check API keys and connectivity.\")\nException: All providers failed. Check API keys and connectivity.\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 518, in _generate_google\n    raise ValueError(f\"Google Gemini blocked response. Finish reason: {finish_reason}. Try with different prompt or use another provider.\")\nValueError: Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.\n"
}
{
  "request_id": "REQ-20251109013223139335",
  "timestamp": "2025-11-09T01:32:23.139362",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 13584.1965675354,
  "retry_count": 0,
  "error_type": "SafetyFilterBlocked",
  "error_message": "Google Gemini blocked response. Finish reason: 2",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 792
  },
  "stack_trace": "NoneType: None\n"
}
{
  "request_id": "REQ-20251109013223139335",
  "timestamp": "2025-11-09T01:32:23.139362",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 13584.773540496826,
  "retry_count": 0,
  "error_type": "ValueError",
  "error_message": "Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 792
  },
  "stack_trace": "Traceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 518, in _generate_google\n    raise ValueError(f\"Google Gemini blocked response. Finish reason: {finish_reason}. Try with different prompt or use another provider.\")\nValueError: Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.\n"
}
{
  "request_id": "REQ-20251109013737194292",
  "timestamp": "2025-11-09T01:37:37.194309",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 13591.455698013306,
  "retry_count": 0,
  "error_type": "SafetyFilterBlocked",
  "error_message": "Google Gemini blocked response. Finish reason: 2",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 789
  },
  "stack_trace": "NoneType: None\n"
}
{
  "request_id": "REQ-20251109013737194292",
  "timestamp": "2025-11-09T01:37:37.194309",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 13591.87936782837,
  "retry_count": 0,
  "error_type": "ValueError",
  "error_message": "Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 789
  },
  "stack_trace": "Traceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 518, in _generate_google\n    raise ValueError(f\"Google Gemini blocked response. Finish reason: {finish_reason}. Try with different prompt or use another provider.\")\nValueError: Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.\n"
}
{
  "request_id": "REQ-20251109013750786840",
  "timestamp": "2025-11-09T01:37:50.786851",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 13824.573516845703,
  "retry_count": 0,
  "error_type": "SafetyFilterBlocked",
  "error_message": "Google Gemini blocked response. Finish reason: 2",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 789
  },
  "stack_trace": "Traceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 364, in generate\n    response = self._generate_fallback(prompt, system_prompt, model, temperature, max_tokens)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 700, in _generate_fallback\n    raise Exception(\"All providers failed. Check API keys and connectivity.\")\nException: All providers failed. Check API keys and connectivity.\n"
}
{
  "request_id": "REQ-20251109013750786840",
  "timestamp": "2025-11-09T01:37:50.786851",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 13825.464010238647,
  "retry_count": 0,
  "error_type": "ValueError",
  "error_message": "Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 789
  },
  "stack_trace": "Traceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 364, in generate\n    response = self._generate_fallback(prompt, system_prompt, model, temperature, max_tokens)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 700, in _generate_fallback\n    raise Exception(\"All providers failed. Check API keys and connectivity.\")\nException: All providers failed. Check API keys and connectivity.\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 518, in _generate_google\n    raise ValueError(f\"Google Gemini blocked response. Finish reason: {finish_reason}. Try with different prompt or use another provider.\")\nValueError: Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.\n"
}
{
  "request_id": "REQ-20251109015409656334",
  "timestamp": "2025-11-09T01:54:09.656343",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 13222.979068756104,
  "retry_count": 0,
  "error_type": "SafetyFilterBlocked",
  "error_message": "Google Gemini blocked response. Finish reason: 2",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 793
  },
  "stack_trace": "NoneType: None\n"
}
{
  "request_id": "REQ-20251109015409656334",
  "timestamp": "2025-11-09T01:54:09.656343",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 13223.64068031311,
  "retry_count": 0,
  "error_type": "ValueError",
  "error_message": "Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 793
  },
  "stack_trace": "Traceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 518, in _generate_google\n    raise ValueError(f\"Google Gemini blocked response. Finish reason: {finish_reason}. Try with different prompt or use another provider.\")\nValueError: Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.\n"
}
{
  "request_id": "REQ-20251109015422881034",
  "timestamp": "2025-11-09T01:54:22.881052",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 13955.101251602173,
  "retry_count": 0,
  "error_type": "SafetyFilterBlocked",
  "error_message": "Google Gemini blocked response. Finish reason: 2",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 793
  },
  "stack_trace": "Traceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 364, in generate\n    response = self._generate_fallback(prompt, system_prompt, model, temperature, max_tokens)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 700, in _generate_fallback\n    raise Exception(\"All providers failed. Check API keys and connectivity.\")\nException: All providers failed. Check API keys and connectivity.\n"
}
{
  "request_id": "REQ-20251109015422881034",
  "timestamp": "2025-11-09T01:54:22.881052",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 13955.872058868408,
  "retry_count": 0,
  "error_type": "ValueError",
  "error_message": "Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 793
  },
  "stack_trace": "Traceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 364, in generate\n    response = self._generate_fallback(prompt, system_prompt, model, temperature, max_tokens)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 700, in _generate_fallback\n    raise Exception(\"All providers failed. Check API keys and connectivity.\")\nException: All providers failed. Check API keys and connectivity.\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 518, in _generate_google\n    raise ValueError(f\"Google Gemini blocked response. Finish reason: {finish_reason}. Try with different prompt or use another provider.\")\nValueError: Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.\n"
}
{
  "request_id": "REQ-20251109015758681725",
  "timestamp": "2025-11-09T01:57:58.681739",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 14833.852767944336,
  "retry_count": 0,
  "error_type": "SafetyFilterBlocked",
  "error_message": "Google Gemini blocked response. Finish reason: 2",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 789
  },
  "stack_trace": "NoneType: None\n"
}
{
  "request_id": "REQ-20251109015758681725",
  "timestamp": "2025-11-09T01:57:58.681739",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 14834.572553634644,
  "retry_count": 0,
  "error_type": "ValueError",
  "error_message": "Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 789
  },
  "stack_trace": "Traceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 518, in _generate_google\n    raise ValueError(f\"Google Gemini blocked response. Finish reason: {finish_reason}. Try with different prompt or use another provider.\")\nValueError: Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.\n"
}
{
  "request_id": "REQ-20251109015813516997",
  "timestamp": "2025-11-09T01:58:13.517008",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 14348.818302154541,
  "retry_count": 0,
  "error_type": "SafetyFilterBlocked",
  "error_message": "Google Gemini blocked response. Finish reason: 2",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 789
  },
  "stack_trace": "Traceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 364, in generate\n    response = self._generate_fallback(prompt, system_prompt, model, temperature, max_tokens)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 700, in _generate_fallback\n    raise Exception(\"All providers failed. Check API keys and connectivity.\")\nException: All providers failed. Check API keys and connectivity.\n"
}
{
  "request_id": "REQ-20251109015813516997",
  "timestamp": "2025-11-09T01:58:13.517008",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 14349.718809127808,
  "retry_count": 0,
  "error_type": "ValueError",
  "error_message": "Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 789
  },
  "stack_trace": "Traceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 364, in generate\n    response = self._generate_fallback(prompt, system_prompt, model, temperature, max_tokens)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 700, in _generate_fallback\n    raise Exception(\"All providers failed. Check API keys and connectivity.\")\nException: All providers failed. Check API keys and connectivity.\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 518, in _generate_google\n    raise ValueError(f\"Google Gemini blocked response. Finish reason: {finish_reason}. Try with different prompt or use another provider.\")\nValueError: Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.\n"
}
{
  "request_id": "REQ-20251109015924561818",
  "timestamp": "2025-11-09T01:59:24.561829",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 13821.51985168457,
  "retry_count": 0,
  "error_type": "SafetyFilterBlocked",
  "error_message": "Google Gemini blocked response. Finish reason: 2",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 789
  },
  "stack_trace": "NoneType: None\n"
}
{
  "request_id": "REQ-20251109015924561818",
  "timestamp": "2025-11-09T01:59:24.561829",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 13822.478771209717,
  "retry_count": 0,
  "error_type": "ValueError",
  "error_message": "Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 789
  },
  "stack_trace": "Traceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 518, in _generate_google\n    raise ValueError(f\"Google Gemini blocked response. Finish reason: {finish_reason}. Try with different prompt or use another provider.\")\nValueError: Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.\n"
}
{
  "request_id": "REQ-20251109015938385500",
  "timestamp": "2025-11-09T01:59:38.385529",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 14061.779260635376,
  "retry_count": 0,
  "error_type": "SafetyFilterBlocked",
  "error_message": "Google Gemini blocked response. Finish reason: 2",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 789
  },
  "stack_trace": "Traceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 364, in generate\n    response = self._generate_fallback(prompt, system_prompt, model, temperature, max_tokens)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 700, in _generate_fallback\n    raise Exception(\"All providers failed. Check API keys and connectivity.\")\nException: All providers failed. Check API keys and connectivity.\n"
}
{
  "request_id": "REQ-20251109015938385500",
  "timestamp": "2025-11-09T01:59:38.385529",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 14063.102006912231,
  "retry_count": 0,
  "error_type": "ValueError",
  "error_message": "Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 789
  },
  "stack_trace": "Traceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 364, in generate\n    response = self._generate_fallback(prompt, system_prompt, model, temperature, max_tokens)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 700, in _generate_fallback\n    raise Exception(\"All providers failed. Check API keys and connectivity.\")\nException: All providers failed. Check API keys and connectivity.\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 518, in _generate_google\n    raise ValueError(f\"Google Gemini blocked response. Finish reason: {finish_reason}. Try with different prompt or use another provider.\")\nValueError: Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.\n"
}
{
  "request_id": "REQ-20251109020342040145",
  "timestamp": "2025-11-09T02:03:42.040162",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 13824.984312057495,
  "retry_count": 0,
  "error_type": "SafetyFilterBlocked",
  "error_message": "Google Gemini blocked response. Finish reason: 2",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 793
  },
  "stack_trace": "NoneType: None\n"
}
{
  "request_id": "REQ-20251109020342040145",
  "timestamp": "2025-11-09T02:03:42.040162",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 13825.524806976318,
  "retry_count": 0,
  "error_type": "ValueError",
  "error_message": "Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 793
  },
  "stack_trace": "Traceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 518, in _generate_google\n    raise ValueError(f\"Google Gemini blocked response. Finish reason: {finish_reason}. Try with different prompt or use another provider.\")\nValueError: Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.\n"
}
{
  "request_id": "REQ-20251109020411326412",
  "timestamp": "2025-11-09T02:04:11.326432",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 16051.035404205322,
  "retry_count": 0,
  "error_type": "SafetyFilterBlocked",
  "error_message": "Google Gemini blocked response. Finish reason: 2",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3500,
    "prompt_length": 871
  },
  "stack_trace": "NoneType: None\n"
}
{
  "request_id": "REQ-20251109020411326412",
  "timestamp": "2025-11-09T02:04:11.326432",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 16051.814556121826,
  "retry_count": 0,
  "error_type": "ValueError",
  "error_message": "Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3500,
    "prompt_length": 871
  },
  "stack_trace": "Traceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 518, in _generate_google\n    raise ValueError(f\"Google Gemini blocked response. Finish reason: {finish_reason}. Try with different prompt or use another provider.\")\nValueError: Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.\n"
}
{
  "request_id": "REQ-20251109020427378869",
  "timestamp": "2025-11-09T02:04:27.378885",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 17107.89442062378,
  "retry_count": 0,
  "error_type": "SafetyFilterBlocked",
  "error_message": "Google Gemini blocked response. Finish reason: 2",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3500,
    "prompt_length": 871
  },
  "stack_trace": "Traceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 364, in generate\n    response = self._generate_fallback(prompt, system_prompt, model, temperature, max_tokens)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 700, in _generate_fallback\n    raise Exception(\"All providers failed. Check API keys and connectivity.\")\nException: All providers failed. Check API keys and connectivity.\n"
}
{
  "request_id": "REQ-20251109020427378869",
  "timestamp": "2025-11-09T02:04:27.378885",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 17108.89744758606,
  "retry_count": 0,
  "error_type": "ValueError",
  "error_message": "Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3500,
    "prompt_length": 871
  },
  "stack_trace": "Traceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 364, in generate\n    response = self._generate_fallback(prompt, system_prompt, model, temperature, max_tokens)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 700, in _generate_fallback\n    raise Exception(\"All providers failed. Check API keys and connectivity.\")\nException: All providers failed. Check API keys and connectivity.\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 518, in _generate_google\n    raise ValueError(f\"Google Gemini blocked response. Finish reason: {finish_reason}. Try with different prompt or use another provider.\")\nValueError: Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.\n"
}
{
  "request_id": "REQ-20251109020532340075",
  "timestamp": "2025-11-09T02:05:32.340098",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 15420.164823532104,
  "retry_count": 0,
  "error_type": "SafetyFilterBlocked",
  "error_message": "Google Gemini blocked response. Finish reason: 2",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 792
  },
  "stack_trace": "NoneType: None\n"
}
{
  "request_id": "REQ-20251109020532340075",
  "timestamp": "2025-11-09T02:05:32.340098",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 15421.059846878052,
  "retry_count": 0,
  "error_type": "ValueError",
  "error_message": "Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 792
  },
  "stack_trace": "Traceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 518, in _generate_google\n    raise ValueError(f\"Google Gemini blocked response. Finish reason: {finish_reason}. Try with different prompt or use another provider.\")\nValueError: Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.\n"
}
{
  "request_id": "REQ-20251109020547762224",
  "timestamp": "2025-11-09T02:05:47.762251",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 14130.11360168457,
  "retry_count": 0,
  "error_type": "SafetyFilterBlocked",
  "error_message": "Google Gemini blocked response. Finish reason: 2",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 792
  },
  "stack_trace": "Traceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 364, in generate\n    response = self._generate_fallback(prompt, system_prompt, model, temperature, max_tokens)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 700, in _generate_fallback\n    raise Exception(\"All providers failed. Check API keys and connectivity.\")\nException: All providers failed. Check API keys and connectivity.\n"
}
{
  "request_id": "REQ-20251109020547762224",
  "timestamp": "2025-11-09T02:05:47.762251",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 14130.980968475342,
  "retry_count": 0,
  "error_type": "ValueError",
  "error_message": "Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 792
  },
  "stack_trace": "Traceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 364, in generate\n    response = self._generate_fallback(prompt, system_prompt, model, temperature, max_tokens)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 700, in _generate_fallback\n    raise Exception(\"All providers failed. Check API keys and connectivity.\")\nException: All providers failed. Check API keys and connectivity.\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 518, in _generate_google\n    raise ValueError(f\"Google Gemini blocked response. Finish reason: {finish_reason}. Try with different prompt or use another provider.\")\nValueError: Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.\n"
}
{
  "request_id": "REQ-20251109043752653418",
  "timestamp": "2025-11-09T04:37:52.653444",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 15000.273942947388,
  "retry_count": 0,
  "error_type": "SafetyFilterBlocked",
  "error_message": "Google Gemini blocked response. Finish reason: 2",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 793
  },
  "stack_trace": "NoneType: None\n"
}
{
  "request_id": "REQ-20251109043752653418",
  "timestamp": "2025-11-09T04:37:52.653444",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 15001.717567443848,
  "retry_count": 0,
  "error_type": "ValueError",
  "error_message": "Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 793
  },
  "stack_trace": "Traceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 518, in _generate_google\n    raise ValueError(f\"Google Gemini blocked response. Finish reason: {finish_reason}. Try with different prompt or use another provider.\")\nValueError: Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.\n"
}
{
  "request_id": "REQ-20251109043807656336",
  "timestamp": "2025-11-09T04:38:07.656358",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 13073.96650314331,
  "retry_count": 0,
  "error_type": "SafetyFilterBlocked",
  "error_message": "Google Gemini blocked response. Finish reason: 2",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 793
  },
  "stack_trace": "Traceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 364, in generate\n    response = self._generate_fallback(prompt, system_prompt, model, temperature, max_tokens)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 700, in _generate_fallback\n    raise Exception(\"All providers failed. Check API keys and connectivity.\")\nException: All providers failed. Check API keys and connectivity.\n"
}
{
  "request_id": "REQ-20251109043807656336",
  "timestamp": "2025-11-09T04:38:07.656358",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 13074.57447052002,
  "retry_count": 0,
  "error_type": "ValueError",
  "error_message": "Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 793
  },
  "stack_trace": "Traceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 364, in generate\n    response = self._generate_fallback(prompt, system_prompt, model, temperature, max_tokens)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 700, in _generate_fallback\n    raise Exception(\"All providers failed. Check API keys and connectivity.\")\nException: All providers failed. Check API keys and connectivity.\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 518, in _generate_google\n    raise ValueError(f\"Google Gemini blocked response. Finish reason: {finish_reason}. Try with different prompt or use another provider.\")\nValueError: Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.\n"
}
{
  "request_id": "REQ-20251109044027328425",
  "timestamp": "2025-11-09T04:40:27.328440",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 13965.699434280396,
  "retry_count": 0,
  "error_type": "SafetyFilterBlocked",
  "error_message": "Google Gemini blocked response. Finish reason: 2",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 793
  },
  "stack_trace": "NoneType: None\n"
}
{
  "request_id": "REQ-20251109044027328425",
  "timestamp": "2025-11-09T04:40:27.328440",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 13966.492176055908,
  "retry_count": 0,
  "error_type": "ValueError",
  "error_message": "Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 793
  },
  "stack_trace": "Traceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 518, in _generate_google\n    raise ValueError(f\"Google Gemini blocked response. Finish reason: {finish_reason}. Try with different prompt or use another provider.\")\nValueError: Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.\n"
}
{
  "request_id": "REQ-20251109044041295981",
  "timestamp": "2025-11-09T04:40:41.295997",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 13412.214994430542,
  "retry_count": 0,
  "error_type": "SafetyFilterBlocked",
  "error_message": "Google Gemini blocked response. Finish reason: 2",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 793
  },
  "stack_trace": "Traceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 359, in generate\n    response = self._generate_google(prompt, system_prompt, model, temperature, max_tokens)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 518, in _generate_google\n    raise ValueError(f\"Google Gemini blocked response. Finish reason: {finish_reason}. Try with different prompt or use another provider.\")\nValueError: Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.\n"
}
{
  "request_id": "REQ-20251109044041295981",
  "timestamp": "2025-11-09T04:40:41.295997",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 13413.300037384033,
  "retry_count": 0,
  "error_type": "ValueError",
  "error_message": "Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 793
  },
  "stack_trace": "Traceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 359, in generate\n    response = self._generate_google(prompt, system_prompt, model, temperature, max_tokens)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 518, in _generate_google\n    raise ValueError(f\"Google Gemini blocked response. Finish reason: {finish_reason}. Try with different prompt or use another provider.\")\nValueError: Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 518, in _generate_google\n    raise ValueError(f\"Google Gemini blocked response. Finish reason: {finish_reason}. Try with different prompt or use another provider.\")\nValueError: Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.\n"
}
{
  "request_id": "REQ-20251109044509275803",
  "timestamp": "2025-11-09T04:45:09.275817",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 14118.064880371094,
  "retry_count": 0,
  "error_type": "SafetyFilterBlocked",
  "error_message": "Google Gemini blocked response. Finish reason: 2",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 793
  },
  "stack_trace": "NoneType: None\n"
}
{
  "request_id": "REQ-20251109044509275803",
  "timestamp": "2025-11-09T04:45:09.275817",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 14118.685483932495,
  "retry_count": 0,
  "error_type": "ValueError",
  "error_message": "Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 793
  },
  "stack_trace": "Traceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 519, in _generate_google\n    raise ValueError(f\"Google Gemini blocked response. Finish reason: {finish_reason}. Try with different prompt or use another provider.\")\nValueError: Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.\n"
}
{
  "request_id": "REQ-20251109050014518503",
  "timestamp": "2025-11-09T05:00:14.518519",
  "provider": "google",
  "endpoint": "generate_content_structured",
  "method": "POST",
  "model": "gemini-2.5-pro",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 2011.1417770385742,
  "retry_count": 0,
  "error_type": "ClientError",
  "error_message": "400 INVALID_ARGUMENT. {'error': {'code': 400, 'message': 'The specified schema produces a constraint that has too many states for serving. Typical causes of this error are schemas with lots of text (for example, very long property or enum names), schemas with long array length limits (especially when nested), or schemas using complex value matchers (for example, integers or numbers with minimum/maximum bounds or strings with complex formats like date-time)', 'status': 'INVALID_ARGUMENT'}}",
  "error_code": null,
  "finish_reason": null,
  "user_context": {
    "temperature": 0.7,
    "prompt_length": 1060
  },
  "stack_trace": "Traceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 625, in generate_structured\n    response = client.models.generate_content(\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/.venv/lib/python3.12/site-packages/google/genai/models.py\", line 5056, in generate_content\n    response = self._generate_content(\n               ^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/.venv/lib/python3.12/site-packages/google/genai/models.py\", line 3843, in _generate_content\n    response = self._api_client.request(\n               ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/.venv/lib/python3.12/site-packages/google/genai/_api_client.py\", line 1331, in request\n    response = self._request(http_request, http_options, stream=False)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/.venv/lib/python3.12/site-packages/google/genai/_api_client.py\", line 1167, in _request\n    return self._retry(self._request_once, http_request, stream)  # type: ignore[no-any-return]\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 477, in __call__\n    do = self.iter(retry_state=retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 378, in iter\n    result = action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 420, in exc_check\n    raise retry_exc.reraise()\n          ^^^^^^^^^^^^^^^^^^^\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 187, in reraise\n    raise self.last_attempt.result()\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 480, in __call__\n    result = fn(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/.venv/lib/python3.12/site-packages/google/genai/_api_client.py\", line 1144, in _request_once\n    errors.APIError.raise_for_response(response)\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/.venv/lib/python3.12/site-packages/google/genai/errors.py\", line 108, in raise_for_response\n    raise ClientError(status_code, response_json, response)\ngoogle.genai.errors.ClientError: 400 INVALID_ARGUMENT. {'error': {'code': 400, 'message': 'The specified schema produces a constraint that has too many states for serving. Typical causes of this error are schemas with lots of text (for example, very long property or enum names), schemas with long array length limits (especially when nested), or schemas using complex value matchers (for example, integers or numbers with minimum/maximum bounds or strings with complex formats like date-time)', 'status': 'INVALID_ARGUMENT'}}\n"
}
{
  "request_id": "REQ-20251109050144429735",
  "timestamp": "2025-11-09T05:01:44.429753",
  "provider": "google",
  "endpoint": "generate_content_structured",
  "method": "POST",
  "model": "gemini-2.5-pro",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 8971,
  "input_tokens": 343,
  "output_tokens": 1301,
  "cost_usd": 0.006933750000000001,
  "duration_ms": 32712.358474731445,
  "retry_count": 0,
  "error_type": "TypeError",
  "error_message": "'UsageStats' object is not subscriptable",
  "error_code": null,
  "finish_reason": null,
  "user_context": {
    "temperature": 0.7,
    "prompt_length": 1060
  },
  "stack_trace": "Traceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 664, in generate_structured\n    self.usage_stats[model]['requests'] += 1\n    ~~~~~~~~~~~~~~~~^^^^^^^\nTypeError: 'UsageStats' object is not subscriptable\n"
}
{
  "request_id": "REQ-20251109050339755500",
  "timestamp": "2025-11-09T05:03:39.755519",
  "provider": "google",
  "endpoint": "generate_content_structured",
  "method": "POST",
  "model": "gemini-2.5-pro",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 9535,
  "input_tokens": 343,
  "output_tokens": 1400,
  "cost_usd": 0.0074287500000000005,
  "duration_ms": 28490.91601371765,
  "retry_count": 0,
  "error_type": "TypeError",
  "error_message": "'UsageStats' object is not subscriptable",
  "error_code": null,
  "finish_reason": null,
  "user_context": {
    "temperature": 0.7,
    "prompt_length": 1051
  },
  "stack_trace": "Traceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 664, in generate_structured\n    self.usage_stats[model]['requests'] += 1\n    ~~~~~~~~~~~~~~~~^^^^^^^\nTypeError: 'UsageStats' object is not subscriptable\n"
}
{
  "request_id": "REQ-20251109050408247221",
  "timestamp": "2025-11-09T05:04:08.247230",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-pro",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 26130.005598068237,
  "retry_count": 0,
  "error_type": "SafetyFilterBlocked",
  "error_message": "Google Gemini blocked response. Finish reason: 2",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 1051
  },
  "stack_trace": "NoneType: None\n"
}
{
  "request_id": "REQ-20251109050408247221",
  "timestamp": "2025-11-09T05:04:08.247230",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-pro",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 26130.764484405518,
  "retry_count": 0,
  "error_type": "ValueError",
  "error_message": "Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 1051
  },
  "stack_trace": "Traceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 521, in _generate_google\n    raise ValueError(f\"Google Gemini blocked response. Finish reason: {finish_reason}. Try with different prompt or use another provider.\")\nValueError: Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.\n"
}
{
  "request_id": "REQ-20251109051358065730",
  "timestamp": "2025-11-09T05:13:58.065741",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-pro",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 3751.152753829956,
  "retry_count": 0,
  "error_type": "ResourceExhausted",
  "error_message": "429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 2\nPlease retry in 58.203440362s. [links {\n  description: \"Learn more about Gemini API quotas\"\n  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n}\n, violations {\n  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n  quota_dimensions {\n    key: \"model\"\n    value: \"gemini-2.5-pro\"\n  }\n  quota_dimensions {\n    key: \"location\"\n    value: \"global\"\n  }\n  quota_value: 2\n}\n, retry_delay {\n  seconds: 58\n}\n]",
  "error_code": null,
  "finish_reason": null,
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3500,
    "prompt_length": 1627
  },
  "stack_trace": "Traceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 495, in _generate_google\n    response = gemini_model.generate_content(\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/.venv/lib/python3.12/site-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n    response = self._client.generate_content(\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/.venv/lib/python3.12/site-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 835, in generate_content\n    response = rpc(\n               ^^^^\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/.venv/lib/python3.12/site-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n    return wrapped_func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/.venv/lib/python3.12/site-packages/google/api_core/retry/retry_unary.py\", line 294, in retry_wrapped_func\n    return retry_target(\n           ^^^^^^^^^^^^^\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/.venv/lib/python3.12/site-packages/google/api_core/retry/retry_unary.py\", line 156, in retry_target\n    next_sleep = _retry_error_helper(\n                 ^^^^^^^^^^^^^^^^^^^^\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/.venv/lib/python3.12/site-packages/google/api_core/retry/retry_base.py\", line 214, in _retry_error_helper\n    raise final_exc from source_exc\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/.venv/lib/python3.12/site-packages/google/api_core/retry/retry_unary.py\", line 147, in retry_target\n    result = target()\n             ^^^^^^^^\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/.venv/lib/python3.12/site-packages/google/api_core/timeout.py\", line 130, in func_with_timeout\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/.venv/lib/python3.12/site-packages/google/api_core/grpc_helpers.py\", line 77, in error_remapped_callable\n    raise exceptions.from_grpc_error(exc) from exc\ngoogle.api_core.exceptions.ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 2\nPlease retry in 58.203440362s. [links {\n  description: \"Learn more about Gemini API quotas\"\n  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n}\n, violations {\n  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n  quota_dimensions {\n    key: \"model\"\n    value: \"gemini-2.5-pro\"\n  }\n  quota_dimensions {\n    key: \"location\"\n    value: \"global\"\n  }\n  quota_value: 2\n}\n, retry_delay {\n  seconds: 58\n}\n]\n"
}
{
  "request_id": "REQ-20251109052753753841",
  "timestamp": "2025-11-09T05:27:53.753858",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 16370.678663253784,
  "retry_count": 0,
  "error_type": "SafetyFilterBlocked",
  "error_message": "Google Gemini blocked response. Finish reason: 2",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3500,
    "prompt_length": 1627
  },
  "stack_trace": "NoneType: None\n"
}
{
  "request_id": "REQ-20251109052753753841",
  "timestamp": "2025-11-09T05:27:53.753858",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 16371.355772018433,
  "retry_count": 0,
  "error_type": "ValueError",
  "error_message": "Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3500,
    "prompt_length": 1627
  },
  "stack_trace": "Traceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 526, in _generate_google\n    raise ValueError(f\"Google Gemini blocked response. Finish reason: {finish_reason}. Try with different prompt or use another provider.\")\nValueError: Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.\n"
}
