{
  "request_id": "REQ-20251108221156609710",
  "timestamp": "2025-11-08T22:11:56.609731",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 7433.3555698394775,
  "retry_count": 0,
  "error_type": "SafetyFilterBlocked",
  "error_message": "Google Gemini blocked response. Finish reason: 2",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 1500,
    "prompt_length": 1438
  },
  "stack_trace": "NoneType: None\n"
}
{
  "request_id": "REQ-20251108221156609710",
  "timestamp": "2025-11-08T22:11:56.609731",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 7434.4940185546875,
  "retry_count": 0,
  "error_type": "ValueError",
  "error_message": "Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 1500,
    "prompt_length": 1438
  },
  "stack_trace": "Traceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 431, in _generate_google\n    raise ValueError(f\"Google Gemini blocked response. Finish reason: {finish_reason}. Try with different prompt or use another provider.\")\nValueError: Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.\n"
}
{
  "request_id": "REQ-20251108221204045517",
  "timestamp": "2025-11-08T22:12:04.045538",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 7513.755083084106,
  "retry_count": 0,
  "error_type": "SafetyFilterBlocked",
  "error_message": "Google Gemini blocked response. Finish reason: 2",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 1500,
    "prompt_length": 1438
  },
  "stack_trace": "Traceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 285, in generate\n    response = self._generate_google(prompt, system_prompt, model, temperature, max_tokens)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 431, in _generate_google\n    raise ValueError(f\"Google Gemini blocked response. Finish reason: {finish_reason}. Try with different prompt or use another provider.\")\nValueError: Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.\n"
}
{
  "request_id": "REQ-20251108221204045517",
  "timestamp": "2025-11-08T22:12:04.045538",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 7514.761924743652,
  "retry_count": 0,
  "error_type": "ValueError",
  "error_message": "Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 1500,
    "prompt_length": 1438
  },
  "stack_trace": "Traceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 285, in generate\n    response = self._generate_google(prompt, system_prompt, model, temperature, max_tokens)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 431, in _generate_google\n    raise ValueError(f\"Google Gemini blocked response. Finish reason: {finish_reason}. Try with different prompt or use another provider.\")\nValueError: Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 431, in _generate_google\n    raise ValueError(f\"Google Gemini blocked response. Finish reason: {finish_reason}. Try with different prompt or use another provider.\")\nValueError: Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.\n"
}
{
  "request_id": "REQ-20251108221222246595",
  "timestamp": "2025-11-08T22:12:22.246615",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 8878.979921340942,
  "retry_count": 0,
  "error_type": "SafetyFilterBlocked",
  "error_message": "Google Gemini blocked response. Finish reason: 2",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 1500,
    "prompt_length": 1438
  },
  "stack_trace": "NoneType: None\n"
}
{
  "request_id": "REQ-20251108221222246595",
  "timestamp": "2025-11-08T22:12:22.246615",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 8879.650354385376,
  "retry_count": 0,
  "error_type": "ValueError",
  "error_message": "Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 1500,
    "prompt_length": 1438
  },
  "stack_trace": "Traceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 431, in _generate_google\n    raise ValueError(f\"Google Gemini blocked response. Finish reason: {finish_reason}. Try with different prompt or use another provider.\")\nValueError: Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.\n"
}
{
  "request_id": "REQ-20251108230941749659",
  "timestamp": "2025-11-08T23:09:41.749668",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 14388.518810272217,
  "retry_count": 0,
  "error_type": "SafetyFilterBlocked",
  "error_message": "Google Gemini blocked response. Finish reason: 2",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 1438
  },
  "stack_trace": "NoneType: None\n"
}
{
  "request_id": "REQ-20251108230941749659",
  "timestamp": "2025-11-08T23:09:41.749668",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 14389.219522476196,
  "retry_count": 0,
  "error_type": "ValueError",
  "error_message": "Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 1438
  },
  "stack_trace": "Traceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 485, in _generate_google\n    raise ValueError(f\"Google Gemini blocked response. Finish reason: {finish_reason}. Try with different prompt or use another provider.\")\nValueError: Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.\n"
}
{
  "request_id": "REQ-20251108230956139937",
  "timestamp": "2025-11-08T23:09:56.139953",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 14948.055267333984,
  "retry_count": 0,
  "error_type": "SafetyFilterBlocked",
  "error_message": "Google Gemini blocked response. Finish reason: 2",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 1438
  },
  "stack_trace": "Traceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 342, in generate\n    response = self._generate_fallback(prompt, system_prompt, model, temperature, max_tokens)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 667, in _generate_fallback\n    raise Exception(\"All providers failed. Check API keys and connectivity.\")\nException: All providers failed. Check API keys and connectivity.\n"
}
{
  "request_id": "REQ-20251108230956139937",
  "timestamp": "2025-11-08T23:09:56.139953",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 14948.673963546753,
  "retry_count": 0,
  "error_type": "ValueError",
  "error_message": "Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 1438
  },
  "stack_trace": "Traceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 342, in generate\n    response = self._generate_fallback(prompt, system_prompt, model, temperature, max_tokens)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 667, in _generate_fallback\n    raise Exception(\"All providers failed. Check API keys and connectivity.\")\nException: All providers failed. Check API keys and connectivity.\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 485, in _generate_google\n    raise ValueError(f\"Google Gemini blocked response. Finish reason: {finish_reason}. Try with different prompt or use another provider.\")\nValueError: Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.\n"
}
{
  "request_id": "REQ-20251108231148890046",
  "timestamp": "2025-11-08T23:11:48.890074",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 13918.081045150757,
  "retry_count": 0,
  "error_type": "SafetyFilterBlocked",
  "error_message": "Google Gemini blocked response. Finish reason: 2",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 1438
  },
  "stack_trace": "NoneType: None\n"
}
{
  "request_id": "REQ-20251108231148890046",
  "timestamp": "2025-11-08T23:11:48.890074",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 13918.55239868164,
  "retry_count": 0,
  "error_type": "ValueError",
  "error_message": "Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 1438
  },
  "stack_trace": "Traceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 485, in _generate_google\n    raise ValueError(f\"Google Gemini blocked response. Finish reason: {finish_reason}. Try with different prompt or use another provider.\")\nValueError: Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.\n"
}
{
  "request_id": "REQ-20251108231202809283",
  "timestamp": "2025-11-08T23:12:02.809296",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 14574.926137924194,
  "retry_count": 0,
  "error_type": "SafetyFilterBlocked",
  "error_message": "Google Gemini blocked response. Finish reason: 2",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 1438
  },
  "stack_trace": "Traceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 342, in generate\n    response = self._generate_fallback(prompt, system_prompt, model, temperature, max_tokens)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 667, in _generate_fallback\n    raise Exception(\"All providers failed. Check API keys and connectivity.\")\nException: All providers failed. Check API keys and connectivity.\n"
}
{
  "request_id": "REQ-20251108231202809283",
  "timestamp": "2025-11-08T23:12:02.809296",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 14575.849294662476,
  "retry_count": 0,
  "error_type": "ValueError",
  "error_message": "Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 1438
  },
  "stack_trace": "Traceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 342, in generate\n    response = self._generate_fallback(prompt, system_prompt, model, temperature, max_tokens)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 667, in _generate_fallback\n    raise Exception(\"All providers failed. Check API keys and connectivity.\")\nException: All providers failed. Check API keys and connectivity.\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 485, in _generate_google\n    raise ValueError(f\"Google Gemini blocked response. Finish reason: {finish_reason}. Try with different prompt or use another provider.\")\nValueError: Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.\n"
}
{
  "request_id": "REQ-20251108231320850218",
  "timestamp": "2025-11-08T23:13:20.850226",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 14732.76424407959,
  "retry_count": 0,
  "error_type": "SafetyFilterBlocked",
  "error_message": "Google Gemini blocked response. Finish reason: 2",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 1652
  },
  "stack_trace": "NoneType: None\n"
}
{
  "request_id": "REQ-20251108231320850218",
  "timestamp": "2025-11-08T23:13:20.850226",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 14733.43539237976,
  "retry_count": 0,
  "error_type": "ValueError",
  "error_message": "Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 1652
  },
  "stack_trace": "Traceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 485, in _generate_google\n    raise ValueError(f\"Google Gemini blocked response. Finish reason: {finish_reason}. Try with different prompt or use another provider.\")\nValueError: Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.\n"
}
{
  "request_id": "REQ-20251108231349307379",
  "timestamp": "2025-11-08T23:13:49.307391",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 14026.033163070679,
  "retry_count": 0,
  "error_type": "SafetyFilterBlocked",
  "error_message": "Google Gemini blocked response. Finish reason: 2",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 1661
  },
  "stack_trace": "NoneType: None\n"
}
{
  "request_id": "REQ-20251108231349307379",
  "timestamp": "2025-11-08T23:13:49.307391",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 14026.97467803955,
  "retry_count": 0,
  "error_type": "ValueError",
  "error_message": "Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 1661
  },
  "stack_trace": "Traceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 485, in _generate_google\n    raise ValueError(f\"Google Gemini blocked response. Finish reason: {finish_reason}. Try with different prompt or use another provider.\")\nValueError: Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.\n"
}
{
  "request_id": "REQ-20251108231403335466",
  "timestamp": "2025-11-08T23:14:03.335491",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 14743.234157562256,
  "retry_count": 0,
  "error_type": "SafetyFilterBlocked",
  "error_message": "Google Gemini blocked response. Finish reason: 2",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 1661
  },
  "stack_trace": "Traceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 342, in generate\n    response = self._generate_fallback(prompt, system_prompt, model, temperature, max_tokens)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 667, in _generate_fallback\n    raise Exception(\"All providers failed. Check API keys and connectivity.\")\nException: All providers failed. Check API keys and connectivity.\n"
}
{
  "request_id": "REQ-20251108231403335466",
  "timestamp": "2025-11-08T23:14:03.335491",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 14743.883848190308,
  "retry_count": 0,
  "error_type": "ValueError",
  "error_message": "Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 1661
  },
  "stack_trace": "Traceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 342, in generate\n    response = self._generate_fallback(prompt, system_prompt, model, temperature, max_tokens)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 667, in _generate_fallback\n    raise Exception(\"All providers failed. Check API keys and connectivity.\")\nException: All providers failed. Check API keys and connectivity.\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 485, in _generate_google\n    raise ValueError(f\"Google Gemini blocked response. Finish reason: {finish_reason}. Try with different prompt or use another provider.\")\nValueError: Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.\n"
}
{
  "request_id": "REQ-20251108231418081286",
  "timestamp": "2025-11-08T23:14:18.081297",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 14499.484300613403,
  "retry_count": 0,
  "error_type": "SafetyFilterBlocked",
  "error_message": "Google Gemini blocked response. Finish reason: 2",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 1052
  },
  "stack_trace": "NoneType: None\n"
}
{
  "request_id": "REQ-20251108231418081286",
  "timestamp": "2025-11-08T23:14:18.081297",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 14500.109672546387,
  "retry_count": 0,
  "error_type": "ValueError",
  "error_message": "Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 1052
  },
  "stack_trace": "Traceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 485, in _generate_google\n    raise ValueError(f\"Google Gemini blocked response. Finish reason: {finish_reason}. Try with different prompt or use another provider.\")\nValueError: Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.\n"
}
{
  "request_id": "REQ-20251108232245299631",
  "timestamp": "2025-11-08T23:22:45.299665",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 13691.915035247803,
  "retry_count": 0,
  "error_type": "SafetyFilterBlocked",
  "error_message": "Google Gemini blocked response. Finish reason: 2",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 1661
  },
  "stack_trace": "NoneType: None\n"
}
{
  "request_id": "REQ-20251108232245299631",
  "timestamp": "2025-11-08T23:22:45.299665",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 13692.56329536438,
  "retry_count": 0,
  "error_type": "ValueError",
  "error_message": "Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 1661
  },
  "stack_trace": "Traceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 485, in _generate_google\n    raise ValueError(f\"Google Gemini blocked response. Finish reason: {finish_reason}. Try with different prompt or use another provider.\")\nValueError: Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.\n"
}
{
  "request_id": "REQ-20251108232258993467",
  "timestamp": "2025-11-08T23:22:58.993484",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 14539.292812347412,
  "retry_count": 0,
  "error_type": "SafetyFilterBlocked",
  "error_message": "Google Gemini blocked response. Finish reason: 2",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 1661
  },
  "stack_trace": "Traceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 342, in generate\n    response = self._generate_fallback(prompt, system_prompt, model, temperature, max_tokens)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 667, in _generate_fallback\n    raise Exception(\"All providers failed. Check API keys and connectivity.\")\nException: All providers failed. Check API keys and connectivity.\n"
}
{
  "request_id": "REQ-20251108232258993467",
  "timestamp": "2025-11-08T23:22:58.993484",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 14540.222883224487,
  "retry_count": 0,
  "error_type": "ValueError",
  "error_message": "Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 1661
  },
  "stack_trace": "Traceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 342, in generate\n    response = self._generate_fallback(prompt, system_prompt, model, temperature, max_tokens)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 667, in _generate_fallback\n    raise Exception(\"All providers failed. Check API keys and connectivity.\")\nException: All providers failed. Check API keys and connectivity.\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 485, in _generate_google\n    raise ValueError(f\"Google Gemini blocked response. Finish reason: {finish_reason}. Try with different prompt or use another provider.\")\nValueError: Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.\n"
}
{
  "request_id": "REQ-20251108232313536132",
  "timestamp": "2025-11-08T23:23:13.536148",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 14218.063354492188,
  "retry_count": 0,
  "error_type": "SafetyFilterBlocked",
  "error_message": "Google Gemini blocked response. Finish reason: 2",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 1661
  },
  "stack_trace": "NoneType: None\n"
}
{
  "request_id": "REQ-20251108232313536132",
  "timestamp": "2025-11-08T23:23:13.536148",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 14218.74213218689,
  "retry_count": 0,
  "error_type": "ValueError",
  "error_message": "Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 1661
  },
  "stack_trace": "Traceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 485, in _generate_google\n    raise ValueError(f\"Google Gemini blocked response. Finish reason: {finish_reason}. Try with different prompt or use another provider.\")\nValueError: Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.\n"
}
{
  "request_id": "REQ-20251108232327755536",
  "timestamp": "2025-11-08T23:23:27.755551",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 13911.49640083313,
  "retry_count": 0,
  "error_type": "SafetyFilterBlocked",
  "error_message": "Google Gemini blocked response. Finish reason: 2",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 1661
  },
  "stack_trace": "Traceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 342, in generate\n    response = self._generate_fallback(prompt, system_prompt, model, temperature, max_tokens)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 667, in _generate_fallback\n    raise Exception(\"All providers failed. Check API keys and connectivity.\")\nException: All providers failed. Check API keys and connectivity.\n"
}
{
  "request_id": "REQ-20251108232327755536",
  "timestamp": "2025-11-08T23:23:27.755551",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 13912.383317947388,
  "retry_count": 0,
  "error_type": "ValueError",
  "error_message": "Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 1661
  },
  "stack_trace": "Traceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 342, in generate\n    response = self._generate_fallback(prompt, system_prompt, model, temperature, max_tokens)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 667, in _generate_fallback\n    raise Exception(\"All providers failed. Check API keys and connectivity.\")\nException: All providers failed. Check API keys and connectivity.\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 485, in _generate_google\n    raise ValueError(f\"Google Gemini blocked response. Finish reason: {finish_reason}. Try with different prompt or use another provider.\")\nValueError: Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.\n"
}
{
  "request_id": "REQ-20251108232401658885",
  "timestamp": "2025-11-08T23:24:01.658904",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 14134.556770324707,
  "retry_count": 0,
  "error_type": "SafetyFilterBlocked",
  "error_message": "Google Gemini blocked response. Finish reason: 2",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 1661
  },
  "stack_trace": "NoneType: None\n"
}
{
  "request_id": "REQ-20251108232401658885",
  "timestamp": "2025-11-08T23:24:01.658904",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 14135.067701339722,
  "retry_count": 0,
  "error_type": "ValueError",
  "error_message": "Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 1661
  },
  "stack_trace": "Traceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 485, in _generate_google\n    raise ValueError(f\"Google Gemini blocked response. Finish reason: {finish_reason}. Try with different prompt or use another provider.\")\nValueError: Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.\n"
}
{
  "request_id": "REQ-20251108232415794682",
  "timestamp": "2025-11-08T23:24:15.794696",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 13820.541143417358,
  "retry_count": 0,
  "error_type": "SafetyFilterBlocked",
  "error_message": "Google Gemini blocked response. Finish reason: 2",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 1661
  },
  "stack_trace": "Traceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 342, in generate\n    response = self._generate_fallback(prompt, system_prompt, model, temperature, max_tokens)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 667, in _generate_fallback\n    raise Exception(\"All providers failed. Check API keys and connectivity.\")\nException: All providers failed. Check API keys and connectivity.\n"
}
{
  "request_id": "REQ-20251108232415794682",
  "timestamp": "2025-11-08T23:24:15.794696",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 13821.577072143555,
  "retry_count": 0,
  "error_type": "ValueError",
  "error_message": "Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 1661
  },
  "stack_trace": "Traceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 342, in generate\n    response = self._generate_fallback(prompt, system_prompt, model, temperature, max_tokens)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 667, in _generate_fallback\n    raise Exception(\"All providers failed. Check API keys and connectivity.\")\nException: All providers failed. Check API keys and connectivity.\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 485, in _generate_google\n    raise ValueError(f\"Google Gemini blocked response. Finish reason: {finish_reason}. Try with different prompt or use another provider.\")\nValueError: Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.\n"
}
{
  "request_id": "REQ-20251108232429618976",
  "timestamp": "2025-11-08T23:24:29.618995",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 14024.714946746826,
  "retry_count": 0,
  "error_type": "SafetyFilterBlocked",
  "error_message": "Google Gemini blocked response. Finish reason: 2",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 1661
  },
  "stack_trace": "NoneType: None\n"
}
{
  "request_id": "REQ-20251108232429618976",
  "timestamp": "2025-11-08T23:24:29.618995",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 14025.407552719116,
  "retry_count": 0,
  "error_type": "ValueError",
  "error_message": "Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 1661
  },
  "stack_trace": "Traceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 485, in _generate_google\n    raise ValueError(f\"Google Gemini blocked response. Finish reason: {finish_reason}. Try with different prompt or use another provider.\")\nValueError: Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.\n"
}
{
  "request_id": "REQ-20251108232443645249",
  "timestamp": "2025-11-08T23:24:43.645270",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 13720.102548599243,
  "retry_count": 0,
  "error_type": "SafetyFilterBlocked",
  "error_message": "Google Gemini blocked response. Finish reason: 2",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 1661
  },
  "stack_trace": "Traceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 342, in generate\n    response = self._generate_fallback(prompt, system_prompt, model, temperature, max_tokens)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 667, in _generate_fallback\n    raise Exception(\"All providers failed. Check API keys and connectivity.\")\nException: All providers failed. Check API keys and connectivity.\n"
}
{
  "request_id": "REQ-20251108232443645249",
  "timestamp": "2025-11-08T23:24:43.645270",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 13720.95513343811,
  "retry_count": 0,
  "error_type": "ValueError",
  "error_message": "Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 1661
  },
  "stack_trace": "Traceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 342, in generate\n    response = self._generate_fallback(prompt, system_prompt, model, temperature, max_tokens)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 667, in _generate_fallback\n    raise Exception(\"All providers failed. Check API keys and connectivity.\")\nException: All providers failed. Check API keys and connectivity.\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 485, in _generate_google\n    raise ValueError(f\"Google Gemini blocked response. Finish reason: {finish_reason}. Try with different prompt or use another provider.\")\nValueError: Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.\n"
}
{
  "request_id": "REQ-20251108232457368551",
  "timestamp": "2025-11-08T23:24:57.368568",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 14217.930316925049,
  "retry_count": 0,
  "error_type": "SafetyFilterBlocked",
  "error_message": "Google Gemini blocked response. Finish reason: 2",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 1661
  },
  "stack_trace": "NoneType: None\n"
}
{
  "request_id": "REQ-20251108232457368551",
  "timestamp": "2025-11-08T23:24:57.368568",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 14218.523502349854,
  "retry_count": 0,
  "error_type": "ValueError",
  "error_message": "Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 1661
  },
  "stack_trace": "Traceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 485, in _generate_google\n    raise ValueError(f\"Google Gemini blocked response. Finish reason: {finish_reason}. Try with different prompt or use another provider.\")\nValueError: Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.\n"
}
{
  "request_id": "REQ-20251108232511587920",
  "timestamp": "2025-11-08T23:25:11.587936",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 14039.858102798462,
  "retry_count": 0,
  "error_type": "SafetyFilterBlocked",
  "error_message": "Google Gemini blocked response. Finish reason: 2",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 1661
  },
  "stack_trace": "Traceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 342, in generate\n    response = self._generate_fallback(prompt, system_prompt, model, temperature, max_tokens)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 667, in _generate_fallback\n    raise Exception(\"All providers failed. Check API keys and connectivity.\")\nException: All providers failed. Check API keys and connectivity.\n"
}
{
  "request_id": "REQ-20251108232511587920",
  "timestamp": "2025-11-08T23:25:11.587936",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 14040.525674819946,
  "retry_count": 0,
  "error_type": "ValueError",
  "error_message": "Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 1661
  },
  "stack_trace": "Traceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 342, in generate\n    response = self._generate_fallback(prompt, system_prompt, model, temperature, max_tokens)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 667, in _generate_fallback\n    raise Exception(\"All providers failed. Check API keys and connectivity.\")\nException: All providers failed. Check API keys and connectivity.\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 485, in _generate_google\n    raise ValueError(f\"Google Gemini blocked response. Finish reason: {finish_reason}. Try with different prompt or use another provider.\")\nValueError: Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.\n"
}
{
  "request_id": "REQ-20251108232525630034",
  "timestamp": "2025-11-08T23:25:25.630045",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 13552.759885787964,
  "retry_count": 0,
  "error_type": "SafetyFilterBlocked",
  "error_message": "Google Gemini blocked response. Finish reason: 2",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 1661
  },
  "stack_trace": "NoneType: None\n"
}
{
  "request_id": "REQ-20251108232525630034",
  "timestamp": "2025-11-08T23:25:25.630045",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 13553.47728729248,
  "retry_count": 0,
  "error_type": "ValueError",
  "error_message": "Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 1661
  },
  "stack_trace": "Traceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 485, in _generate_google\n    raise ValueError(f\"Google Gemini blocked response. Finish reason: {finish_reason}. Try with different prompt or use another provider.\")\nValueError: Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.\n"
}
{
  "request_id": "REQ-20251108232539184829",
  "timestamp": "2025-11-08T23:25:39.184858",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 14534.019470214844,
  "retry_count": 0,
  "error_type": "SafetyFilterBlocked",
  "error_message": "Google Gemini blocked response. Finish reason: 2",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 1661
  },
  "stack_trace": "Traceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 342, in generate\n    response = self._generate_fallback(prompt, system_prompt, model, temperature, max_tokens)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 667, in _generate_fallback\n    raise Exception(\"All providers failed. Check API keys and connectivity.\")\nException: All providers failed. Check API keys and connectivity.\n"
}
{
  "request_id": "REQ-20251108232539184829",
  "timestamp": "2025-11-08T23:25:39.184858",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 14534.639835357666,
  "retry_count": 0,
  "error_type": "ValueError",
  "error_message": "Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 1661
  },
  "stack_trace": "Traceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 342, in generate\n    response = self._generate_fallback(prompt, system_prompt, model, temperature, max_tokens)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 667, in _generate_fallback\n    raise Exception(\"All providers failed. Check API keys and connectivity.\")\nException: All providers failed. Check API keys and connectivity.\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 485, in _generate_google\n    raise ValueError(f\"Google Gemini blocked response. Finish reason: {finish_reason}. Try with different prompt or use another provider.\")\nValueError: Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.\n"
}
{
  "request_id": "REQ-20251108232553723203",
  "timestamp": "2025-11-08T23:25:53.723215",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 14223.787784576416,
  "retry_count": 0,
  "error_type": "SafetyFilterBlocked",
  "error_message": "Google Gemini blocked response. Finish reason: 2",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 1661
  },
  "stack_trace": "NoneType: None\n"
}
{
  "request_id": "REQ-20251108232553723203",
  "timestamp": "2025-11-08T23:25:53.723215",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 14224.317789077759,
  "retry_count": 0,
  "error_type": "ValueError",
  "error_message": "Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 1661
  },
  "stack_trace": "Traceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 485, in _generate_google\n    raise ValueError(f\"Google Gemini blocked response. Finish reason: {finish_reason}. Try with different prompt or use another provider.\")\nValueError: Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.\n"
}
{
  "request_id": "REQ-20251108232607947997",
  "timestamp": "2025-11-08T23:26:07.948012",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 14296.151638031006,
  "retry_count": 0,
  "error_type": "SafetyFilterBlocked",
  "error_message": "Google Gemini blocked response. Finish reason: 2",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 1661
  },
  "stack_trace": "Traceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 342, in generate\n    response = self._generate_fallback(prompt, system_prompt, model, temperature, max_tokens)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 667, in _generate_fallback\n    raise Exception(\"All providers failed. Check API keys and connectivity.\")\nException: All providers failed. Check API keys and connectivity.\n"
}
{
  "request_id": "REQ-20251108232607947997",
  "timestamp": "2025-11-08T23:26:07.948012",
  "provider": "google",
  "endpoint": "generate_content",
  "method": "POST",
  "model": "gemini-2.5-flash",
  "prompt_length": 0,
  "temperature": null,
  "max_tokens": null,
  "status": "error",
  "response_length": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "cost_usd": 0.0,
  "duration_ms": 14297.232866287231,
  "retry_count": 0,
  "error_type": "ValueError",
  "error_message": "Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.",
  "error_code": null,
  "finish_reason": "2",
  "user_context": {
    "temperature": 0.7,
    "max_tokens": 3000,
    "prompt_length": 1661
  },
  "stack_trace": "Traceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 342, in generate\n    response = self._generate_fallback(prompt, system_prompt, model, temperature, max_tokens)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 667, in _generate_fallback\n    raise Exception(\"All providers failed. Check API keys and connectivity.\")\nException: All providers failed. Check API keys and connectivity.\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/brunomoya/development/hackuab2025/TalentGapAnalyzer-UABTheHack-1/api/services/ai_service.py\", line 485, in _generate_google\n    raise ValueError(f\"Google Gemini blocked response. Finish reason: {finish_reason}. Try with different prompt or use another provider.\")\nValueError: Google Gemini blocked response. Finish reason: 2. Try with different prompt or use another provider.\n"
}
